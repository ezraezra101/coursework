{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 : Predicting Business Cateogries using Checkin Data in Yelp (100 points)\n",
    "\n",
    "*------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the [yelp dataset](https://www.yelp.com/dataset_challenge)\n",
    "* We need to use the following two files in the dataset:\n",
    "    * yelp_academic_dataset_business.json\n",
    "    * yelp_academic_dataset_checkin.json\n",
    "* Each file in the dataset is composed of one json-object per line. \n",
    "\n",
    "## Business Objects\n",
    "\n",
    "Business objects contain basic information about local businesses. The fields are as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "  'type': 'business',\n",
    "  'business_id': (a unique identifier for this business),\n",
    "  'name': (the full business name),\n",
    "  'neighborhoods': (a list of neighborhood names, might be empty),\n",
    "  'full_address': (localized address),\n",
    "  'city': (city),\n",
    "  'state': (state),\n",
    "  'latitude': (latitude),\n",
    "  'longitude': (longitude),\n",
    "  'stars': (star rating, rounded to half-stars),\n",
    "  'review_count': (review count),\n",
    "  'photo_url': (photo url),\n",
    "  'categories': [(localized category names)]\n",
    "  'open': (is the business still open for business?),\n",
    "  'schools': (nearby universities),\n",
    "  'url': (yelp url)\n",
    "}\n",
    "```\n",
    "## Checkin Objects\n",
    "```json\n",
    "{\n",
    "    'type': 'checkin',\n",
    "    'business_id': (encrypted business id),\n",
    "    'checkin_info': {\n",
    "        '0-0': (number of checkins from 00:00 to 01:00 on all Sundays),\n",
    "        '1-0': (number of checkins from 01:00 to 02:00 on all Sundays),\n",
    "        ...\n",
    "        '14-4': (number of checkins from 14:00 to 15:00 on all Thursdays),\n",
    "        ...\n",
    "        '23-6': (number of checkins from 23:00 to 00:00 on all Saturdays)\n",
    "    }, # if there was no checkin for a hour-day block it will not be in the dict\n",
    "}\n",
    "```\n",
    "* The task is to predict the 'business category'  for a given business based upon its checkin_info. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (20 points): Load and explore Yelp Data\n",
    "## Problem 1.1 (5 points): load the checkin objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61049\n",
      "{\n",
      " \"checkin_info\": {\n",
      "  \"9-5\": 1, \n",
      "  \"7-5\": 1, \n",
      "  \"13-3\": 1, \n",
      "  \"17-6\": 1, \n",
      "  \"13-0\": 1, \n",
      "  \"17-3\": 1, \n",
      "  \"10-0\": 1, \n",
      "  \"18-4\": 1, \n",
      "  \"14-6\": 1\n",
      " }, \n",
      " \"type\": \"checkin\", \n",
      " \"business_id\": \"cE27W9VPgO88Qxe4ol6y_g\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#------------------------\n",
    "filename_checkin = \"yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_checkin.json\"\n",
    "\n",
    "list_checkin = []\n",
    "with open(filename_checkin) as file_checkin:\n",
    "    for line in file_checkin:\n",
    "        try:\n",
    "            list_checkin.append(json.loads(line))\n",
    "        except:\n",
    "            print \"This line is broken:{:}\".format(line)\n",
    "\n",
    "\n",
    "#list_checkin <-- your list\n",
    "#------------------------\n",
    "\n",
    "# print the number of checkin objects\n",
    "print len(list_checkin)\n",
    "# print the first checkin object\n",
    "print json.dumps(list_checkin[0], indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.2 (5 points): load the business objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85901\n",
      "{\n",
      " \"city\": \"Dravosburg\", \n",
      " \"review_count\": 7, \n",
      " \"name\": \"Mr Hoagie\", \n",
      " \"neighborhoods\": [], \n",
      " \"type\": \"business\", \n",
      " \"business_id\": \"5UmKMjUEUNdYWqANhGckJw\", \n",
      " \"full_address\": \"4734 Lebanon Church Rd\\nDravosburg, PA 15034\", \n",
      " \"hours\": {\n",
      "  \"Tuesday\": {\n",
      "   \"close\": \"21:00\", \n",
      "   \"open\": \"11:00\"\n",
      "  }, \n",
      "  \"Friday\": {\n",
      "   \"close\": \"21:00\", \n",
      "   \"open\": \"11:00\"\n",
      "  }, \n",
      "  \"Monday\": {\n",
      "   \"close\": \"21:00\", \n",
      "   \"open\": \"11:00\"\n",
      "  }, \n",
      "  \"Wednesday\": {\n",
      "   \"close\": \"21:00\", \n",
      "   \"open\": \"11:00\"\n",
      "  }, \n",
      "  \"Thursday\": {\n",
      "   \"close\": \"21:00\", \n",
      "   \"open\": \"11:00\"\n",
      "  }\n",
      " }, \n",
      " \"state\": \"PA\", \n",
      " \"longitude\": -79.9007057, \n",
      " \"stars\": 3.5, \n",
      " \"latitude\": 40.3543266, \n",
      " \"attributes\": {\n",
      "  \"Take-out\": true, \n",
      "  \"Drive-Thru\": false, \n",
      "  \"Outdoor Seating\": false, \n",
      "  \"Caters\": false, \n",
      "  \"Noise Level\": \"average\", \n",
      "  \"Parking\": {\n",
      "   \"garage\": false, \n",
      "   \"street\": false, \n",
      "   \"validated\": false, \n",
      "   \"lot\": false, \n",
      "   \"valet\": false\n",
      "  }, \n",
      "  \"Delivery\": false, \n",
      "  \"Attire\": \"casual\", \n",
      "  \"Has TV\": false, \n",
      "  \"Price Range\": 1, \n",
      "  \"Good For\": {\n",
      "   \"dessert\": false, \n",
      "   \"latenight\": false, \n",
      "   \"lunch\": false, \n",
      "   \"dinner\": false, \n",
      "   \"breakfast\": false, \n",
      "   \"brunch\": false\n",
      "  }, \n",
      "  \"Takes Reservations\": false, \n",
      "  \"Ambience\": {\n",
      "   \"romantic\": false, \n",
      "   \"intimate\": false, \n",
      "   \"classy\": false, \n",
      "   \"hipster\": false, \n",
      "   \"divey\": false, \n",
      "   \"touristy\": false, \n",
      "   \"trendy\": false, \n",
      "   \"upscale\": false, \n",
      "   \"casual\": false\n",
      "  }, \n",
      "  \"Waiter Service\": false, \n",
      "  \"Accepts Credit Cards\": true, \n",
      "  \"Good for Kids\": true, \n",
      "  \"Good For Groups\": true, \n",
      "  \"Alcohol\": \"none\"\n",
      " }, \n",
      " \"open\": true, \n",
      " \"categories\": [\n",
      "  \"Fast Food\", \n",
      "  \"Restaurants\"\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#------------------------\n",
    "\n",
    "filename_business = \"yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_business.json\"\n",
    "\n",
    "list_business = []\n",
    "with open(filename_business) as file_business:\n",
    "    for line in file_business:\n",
    "        try:\n",
    "            list_business.append(json.loads(line))\n",
    "        except:\n",
    "            print \"This line is broken:{:}\".format(line)\n",
    "\n",
    "#------------------------\n",
    "\n",
    "# print the number of business objects\n",
    "print len(list_business)\n",
    "# print the first business object\n",
    "print json.dumps(list_business[0], indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.3 (5 points) Finding the most popular business categories\n",
    "* print the top 10 most popular business categories in the dataset and their counts (i.e., how many business objects in each category). Here we say a category is \"popular\" = more business objects in this category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26729 businesses in the Restaurants category\n",
      "There are 12444 businesses in the Shopping category\n",
      "There are 10143 businesses in the Food category\n",
      "There are  7490 businesses in the Beauty & Spas category\n",
      "There are  6106 businesses in the Health & Medical category\n",
      "There are  5866 businesses in the Home Services category\n",
      "There are  5507 businesses in the Nightlife category\n",
      "There are  4888 businesses in the Automotive category\n",
      "There are  4727 businesses in the Bars category\n",
      "There are  4041 businesses in the Local Services category\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "c = collections.Counter()\n",
    "\n",
    "for business in list_business:\n",
    "    c.update(business['categories'])\n",
    "\n",
    "for cat, count in c.most_common(10):\n",
    "    print \"There are {:5d} businesses in the {:} category\".format(count, cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.4 (5 points) Finding the most popular business objects\n",
    "* print the top 10 most popular business objects in the dataset and their counts (i.e., how many checkins in total for each business object). \n",
    "Here we say a business object is \"popular\" =  more checkins in this business object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McCarran International Airport has 85243 checkins\n",
      "Phoenix Sky Harbor International Airport - PHX has 75705 checkins\n",
      "Charlotte Douglas International Airport has 33293 checkins\n",
      "The Cosmopolitan of Las Vegas has 29095 checkins\n",
      "ARIA Hotel & Casino has 19566 checkins\n",
      "The Venetian Las Vegas has 19434 checkins\n",
      "MGM Grand Hotel has 19201 checkins\n",
      "Caesars Palace Las Vegas Hotel & Casino has 18948 checkins\n",
      "Bellagio Hotel has 18914 checkins\n",
      "Kung Fu Tea has 17810 checkins\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "c = collections.Counter()\n",
    "\n",
    "for checkin in list_checkin:\n",
    "    c[checkin['business_id']] = sum(checkin['checkin_info'].values())\n",
    "\n",
    "dict_business = {}\n",
    "for business in list_business:\n",
    "    dict_business[business['business_id']] = business\n",
    "\n",
    "for business_id, count in c.most_common(10):\n",
    "    business = dict_business[business_id]\n",
    "    print \"{:} has {:5d} checkins\".format(business['name'], count)\n",
    "    # I'm not printing these out because they take up a *lot* of space\n",
    "    # print json.dumps(business, indent=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (20 points) Pick one of business category from the top 5 most popular categories and prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.1 (10 points) extract the feature vectors for business objects using checkin information.\n",
    "* Each business object should be represented by a vector of numbers, indicating the number checkins in each time slots.\n",
    "\n",
    "For example, suppose we have a dataset of three business objects.\n",
    "* checkin_info for business A:{'0-0': 5, '23-6': 6} \n",
    "* checkin_info for business B:{'0-0': 7, '21-6': 9} \n",
    "* checkin_info for business C:{'2-2': 8, '23-6': 3}\n",
    "\n",
    "The feature vectors for the three objects should be \n",
    "* A: (5, 0, 0, 6)\n",
    "* B: (7, 0, 9, 0)\n",
    "* C: (0, 8, 0, 3)\n",
    "\n",
    "The values in the feature vector corespond to the numbers of checkins in time slots(\"0-0\", \"2-2\", \"21-6\", \"23-6\") separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_checkin = {}\n",
    "for checkin in list_checkin:\n",
    "    dict_checkin[checkin['business_id']] = checkin\n",
    "\n",
    "dict_business_vector = {}\n",
    "misses = 0\n",
    "\n",
    "# Creates a pretty long vector...\n",
    "categories = [ \"{:}-{:}\".format(i, j) for i in range(24) for j in range(7)]\n",
    "def vector_from_checkin(checkin):\n",
    "    vector = tuple([checkin['checkin_info'].get(category, 0) for category in categories])\n",
    "    return vector\n",
    "\n",
    "for business in list_business:\n",
    "    id = business['business_id']\n",
    "    if(id in dict_checkin):\n",
    "        dict_business_vector[id] = vector_from_checkin(dict_checkin[id])\n",
    "    else:\n",
    "        dict_business_vector[id] = vector_from_checkin({'checkin_info':{}})\n",
    "        misses += 1\n",
    "        \n",
    "\n",
    "if(misses + len(list_checkin) - len(list_business) !=0):\n",
    "    print(\"There's an error somewhere... we didn't calculate the right number of vectors from the businesses and checkins\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_feature_vectors = [ dict_business_vector[id] for id in sorted(dict_business_vector.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2 (10 points) extract the labels (category)\n",
    "* Choose a category of your choise, for example \"Grocery\", from **the top 5 popular categories**. Note, the example \"Grocery\" may not be among the top 5.\n",
    "* Extract a vector of labels for ** all the business objects in the Problem 2.1**. Note the order of the business objects in Problem 2.1 and 2.2 should be the same.\n",
    "* The label indicates whether or not the business object belongs to the category that you chose (say \"Grocery\" for example). If yes, the value is 1, otherwise -1.\n",
    "\n",
    "For example, suppose we have a dataset of three business objects. Suppose you choose \"Grocery\" as the target category.\n",
    "* categories for business A:{'Grocery', 'Food'} \n",
    "* categories for business B:{'Food', 'Drink'} \n",
    "* categories for business C:{'Grocery'}\n",
    "\n",
    "The labels for the three objects should be \n",
    "* A: 1\n",
    "* B: -1\n",
    "* C: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_category = \"Restaurants\" \n",
    "\n",
    "dict_labels = {}\n",
    "for id in dict_business_vector.keys():\n",
    "    if target_category in dict_business[id]['categories']:\n",
    "        dict_labels[id] = 1\n",
    "    else:\n",
    "        dict_labels[id] = -1\n",
    "\n",
    "\n",
    "list_labels = [ dict_labels[id] for id in sorted(dict_labels.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the dataset into a training set and test set for classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezradavis/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(list_feature_vectors,list_labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 (15 points): Support vector machine (SVM)\n",
    "* Tune the parameters of SVM on the training data to find the best parameter setting. You could tune the following two parameters in SVM ('C', 'kernel') using the cadidate values in the cell below.\n",
    "* Apply the best SVM model to the test data to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear kernel has score 0.718060648391\n",
      "poly kernel has score 0.733368255631\n",
      "rbf kernel has score 0.736103835632\n",
      "sigmoid kernel has score 0.608986671323\n",
      "The best kernel is rbf with a score of 0.736103835632\n",
      "When C=0.001, score=0.689948198591\n",
      "When C=0.01, score=0.689948198591\n",
      "When C=0.1, score=0.689948198591\n",
      "When C=1, score=0.692974797742\n",
      "When C=10, score=0.709446481578\n",
      "When C=100, score=0.660497060707\n",
      "When C=1000, score=0.660380653047\n",
      "The best C is 10 with score 0.709446481578\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "C_choices=[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "kernel_choices=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# Kernel and C (amount we're punishing for an error) are relatively independent, so I can do one after another.\n",
    "\n",
    "# I'm also using a smaller training set for determining the best values\n",
    "#    because longer ones take too much time, and doesn't change that much... hopefully\n",
    "\n",
    "best_kernel = 'bad kernel'\n",
    "best_score = 0\n",
    "for kernel in kernel_choices:\n",
    "    svc = SVC(C=1, kernel=kernel)\n",
    "    svc.fit(X_train[0:1000], y_train[0:1000])\n",
    "    score = svc.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_kernel = kernel\n",
    "    print \"{:} kernel has score {:}\".format(kernel, score)\n",
    "\n",
    "print \"The best kernel is {:} with a score of {:}\".format(best_kernel, best_score)\n",
    "\n",
    "best_C = 'bad choice'\n",
    "best_score = 0\n",
    "for C in C_choices:\n",
    "    svc = SVC(C=C, kernel=best_kernel)\n",
    "    svc.fit(X_train[0:100],y_train[0:100])\n",
    "    score = svc.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_C = C\n",
    "    print \"When C={:}, score={:}\".format(C,score)\n",
    "\n",
    "print \"The best C is {:} with score {:}\".format(best_C, best_score)\n",
    "\n",
    "best_svm_model = SVC(C=best_C, kernel=best_kernel)# the SVM model using the best parameter setting\n",
    "print best_svm_model\n",
    "\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# This will take a while...\n",
    "# Okay... if best_kernel isn't 'linear', then it takes *forever* to train\n",
    "#    \"The fit time complexity is more than quadratic with the number of\n",
    "#    samples which makes it hard to scale to dataset with more than a\n",
    "#    couple of 10000 samples.\" -- http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "# I've found that this starts to take unreasonably long when I go to around 750 values... which is pretty sad (and inaccurate).\n",
    "\n",
    "svc.fit(X_train[0:500], y_train[0:500])\n",
    "\n",
    "y_pred_svm = svc.predict(X_test)# the predicted lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.84      0.78     11854\n",
      "          1       0.46      0.29      0.36      5327\n",
      "\n",
      "avg / total       0.64      0.67      0.65     17181\n",
      "\n",
      "[[9978 1876]\n",
      " [3757 1570]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# evaluate the results\n",
    "print classification_report(y_test, y_pred_svm)\n",
    "print confusion_matrix(y_test, y_pred_svm,labels=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 (45 points): Decision Tree, Bagging, Random Forest\n",
    "## Problem 4.1 (15 points): Decision Tree\n",
    "* Tune the parameters of Decision Tree on the training data to find the best parameter setting. You should tune the  parameter *max_depth* using the cadidate values in the cell below.\n",
    "* Apply the best model to the test data to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-40e76a5b85f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_depth_choices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdepth_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdepth_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth_choices=range(5,25,5)\n",
    "# insert your code here\n",
    "\n",
    "best_score = 0\n",
    "best_tree_model = \"Invalid tree model\"\n",
    "for max_depth in max_depth_choices:\n",
    "    depth_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=max_depth)    \n",
    "    depth_tree.fit(X_train, y_train)\n",
    "    score = depth_tree.score(X_test, y_test)\n",
    "    if(score > best_score):\n",
    "        best_tree_model = depth_tree\n",
    "        best_score = score\n",
    "    print \"Score at depth {:}: {:}\".format(max_depth, score)\n",
    "\n",
    "# the model using the best parameter setting\n",
    "print best_tree_model\n",
    "\n",
    "y_pred_tree = best_tree_model.predict(X_test)# the predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.76      0.93      0.83     11847\n",
      "          1       0.68      0.35      0.46      5334\n",
      "\n",
      "avg / total       0.74      0.75      0.72     17181\n",
      "\n",
      "[[10969   878]\n",
      " [ 3459  1875]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the results\n",
    "print classification_report(y_test, y_pred_tree)\n",
    "print confusion_matrix(y_test, y_pred_tree,labels=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.2 (15 points): Bagging\n",
    "* Tune the parameters of Bagging method on the training data to find the best parameter setting. You could tune the following parameters: max_depth, n_estimators \n",
    "* Apply the best model to the test data to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with 5 samples and 5 estimators: 0.661835748792\n",
      "Score with 5 samples and 10 estimators: 0.685350096036\n",
      "Score with 5 samples and 15 estimators: 0.690704848379\n",
      "Score with 5 samples and 20 estimators: 0.689657179442\n",
      "Score with 10 samples and 5 estimators: 0.682498108376\n",
      "Score with 10 samples and 10 estimators: 0.705022990513\n",
      "Score with 10 samples and 15 estimators: 0.699726442\n",
      "Score with 10 samples and 20 estimators: 0.70281124498\n",
      "Score with 15 samples and 5 estimators: 0.691461498167\n",
      "Score with 15 samples and 10 estimators: 0.710668762005\n",
      "Score with 15 samples and 15 estimators: 0.713695361155\n",
      "Score with 15 samples and 20 estimators: 0.703567894767\n",
      "Score with 20 samples and 5 estimators: 0.685699319015\n",
      "Score with 20 samples and 10 estimators: 0.696408823701\n",
      "Score with 20 samples and 15 estimators: 0.706128863279\n",
      "Score with 20 samples and 20 estimators: 0.709155462429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=15,\n",
      "         n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "max_depth_choices=range(5,25,5)\n",
    "n_estimators_choices=range(5, 25, 5) \n",
    "\n",
    "# insert your code here\n",
    "\n",
    "best_score = 0\n",
    "best_bagging_model = \"Invalid bagging model\"\n",
    "for max_depth in max_depth_choices:\n",
    "    for n_estimators in n_estimators_choices:\n",
    "        model = BaggingClassifier(n_estimators=n_estimators, max_samples=max_depth)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if(score > best_score):\n",
    "            best_bagging_model = model\n",
    "            best_score = score\n",
    "        print \"Score with {:} samples and {:} estimators: {:}\".format(max_depth, n_estimators, score)\n",
    "\n",
    "print best_bagging_model # the model using the best parameter setting\n",
    "\n",
    "y_pred_bagging = best_bagging_model.predict(X_test)# the predicted labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.90      0.81     11847\n",
      "          1       0.57      0.31      0.40      5334\n",
      "\n",
      "avg / total       0.69      0.71      0.68     17181\n",
      "\n",
      "[[10634  1213]\n",
      " [ 3706  1628]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the results\n",
    "print classification_report(y_test, y_pred_bagging)\n",
    "print confusion_matrix(y_test, y_pred_bagging,labels=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 4.3 (15 points): Random Forest\n",
    "* Tune the parameters of Random Forest method on the training data to find the best parameter setting. You could tune the following parameter: max_depth, n_estimators max_features\n",
    "* Apply the best model to the test data to predict the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with 5 samples and 5 estimators: 0.716372737326\n",
      "Score with 5 samples and 5 estimators: 0.725452534777\n",
      "Score with 5 samples and 5 estimators: 0.731854956056\n",
      "Score with 5 samples and 5 estimators: 0.736336650952\n",
      "Score with 5 samples and 10 estimators: 0.721552878179\n",
      "Score with 5 samples and 10 estimators: 0.73383388627\n",
      "Score with 5 samples and 10 estimators: 0.734765147547\n",
      "Score with 5 samples and 10 estimators: 0.73686048542\n",
      "Score with 5 samples and 15 estimators: 0.71212385775\n",
      "Score with 5 samples and 15 estimators: 0.731272917758\n",
      "Score with 5 samples and 15 estimators: 0.733251847972\n",
      "Score with 5 samples and 15 estimators: 0.736103835632\n",
      "Score with 5 samples and 20 estimators: 0.717827833071\n",
      "Score with 5 samples and 20 estimators: 0.732669809673\n",
      "Score with 5 samples and 20 estimators: 0.735521797334\n",
      "Score with 5 samples and 20 estimators: 0.736278447122\n",
      "Score with 10 samples and 5 estimators: 0.734183109249\n",
      "Score with 10 samples and 5 estimators: 0.738606600314\n",
      "Score with 10 samples and 5 estimators: 0.746347709679\n",
      "Score with 10 samples and 5 estimators: 0.746696932658\n",
      "Score with 10 samples and 10 estimators: 0.739537861591\n",
      "Score with 10 samples and 10 estimators: 0.744601594785\n",
      "Score with 10 samples and 10 estimators: 0.749432512659\n",
      "Score with 10 samples and 10 estimators: 0.754787265002\n",
      "Score with 10 samples and 15 estimators: 0.737908154357\n",
      "Score with 10 samples and 15 estimators: 0.750014550957\n",
      "Score with 10 samples and 15 estimators: 0.750771200745\n",
      "Score with 10 samples and 15 estimators: 0.755660322449\n",
      "Score with 10 samples and 20 estimators: 0.735638204994\n",
      "Score with 10 samples and 20 estimators: 0.74914149351\n",
      "Score with 10 samples and 20 estimators: 0.754147022874\n",
      "Score with 10 samples and 20 estimators: 0.756358768407\n",
      "Score with 15 samples and 5 estimators: 0.740119899889\n",
      "Score with 15 samples and 5 estimators: 0.744426983296\n",
      "Score with 15 samples and 5 estimators: 0.751353239043\n",
      "Score with 15 samples and 5 estimators: 0.749025085851\n",
      "Score with 15 samples and 10 estimators: 0.744776206274\n",
      "Score with 15 samples and 10 estimators: 0.75234270415\n",
      "Score with 15 samples and 10 estimators: 0.757231825854\n",
      "Score with 15 samples and 10 estimators: 0.764390896921\n",
      "Score with 15 samples and 15 estimators: 0.745183633083\n",
      "Score with 15 samples and 15 estimators: 0.755194691811\n",
      "Score with 15 samples and 15 estimators: 0.761131482452\n",
      "Score with 15 samples and 15 estimators: 0.763168616495\n",
      "Score with 15 samples and 20 estimators: 0.746289505849\n",
      "Score with 15 samples and 20 estimators: 0.758337698621\n",
      "Score with 15 samples and 20 estimators: 0.760316628834\n",
      "Score with 15 samples and 20 estimators: 0.765263954368\n",
      "Score with 20 samples and 5 estimators: 0.739596065421\n",
      "Score with 20 samples and 5 estimators: 0.745649263722\n",
      "Score with 20 samples and 5 estimators: 0.750189162447\n",
      "Score with 20 samples and 5 estimators: 0.751760665852\n",
      "Score with 20 samples and 10 estimators: 0.747628193935\n",
      "Score with 20 samples and 10 estimators: 0.758686921599\n",
      "Score with 20 samples and 10 estimators: 0.756649787556\n",
      "Score with 20 samples and 10 estimators: 0.761771724579\n",
      "Score with 20 samples and 15 estimators: 0.752982946278\n",
      "Score with 20 samples and 15 estimators: 0.755602118619\n",
      "Score with 20 samples and 15 estimators: 0.763401431814\n",
      "Score with 20 samples and 15 estimators: 0.765613177347\n",
      "Score with 20 samples and 20 estimators: 0.754670857342\n",
      "Score with 20 samples and 20 estimators: 0.763750654793\n",
      "Score with 20 samples and 20 estimators: 0.765787788837\n",
      "Score with 20 samples and 20 estimators: 0.769745649264\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=4, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "max_depth_choices=range(5,25,5)\n",
    "n_estimators_choices=range(5, 25, 5) \n",
    "max_features_choices=range(1,5)\n",
    "\n",
    "# insert your code here\n",
    "best_score = 0\n",
    "best_rf_model = \"Invalid random forest model\"\n",
    "for max_depth in max_depth_choices:\n",
    "    for n_estimators in n_estimators_choices:\n",
    "        for max_features in max_features_choices:\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            if(score > best_score):\n",
    "                best_rf_model = model\n",
    "                best_score = score\n",
    "            print \"Score with {:} samples and {:} estimators: {:}\".format(max_depth, n_estimators, score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the model using the best parameter setting\n",
    "print best_rf_model\n",
    "\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "\n",
    "\n",
    "y_pred_rf = best_rf_model.predict(X_test)# the predicted lables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.77      0.95      0.85     11847\n",
      "          1       0.78      0.36      0.49      5334\n",
      "\n",
      "avg / total       0.77      0.77      0.74     17181\n",
      "\n",
      "[[11311   536]\n",
      " [ 3420  1914]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the results\n",
    "print classification_report(y_test, y_pred_rf)\n",
    "print confusion_matrix(y_test, y_pred_rf,labels=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "  Please submit your notebook file through myWPI, in the Assignment \"Homework 3\"."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
