{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes 1/12/2017\n",
    "\n",
    "*Check that I have **3rd** edition of Algorithms textbook*\n",
    "\n",
    "The 2 lowest HW scores are dropped.\n",
    "\n",
    "Exams are on Monday Feb. 6th and Friday March 3.\n",
    "\n",
    "The website is at http://web.cs.wpi.edu/~gsarkozy/4120/cs4120.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Topics: Design and Analysis\n",
    "- Analysis: (in this class, we mostly care about time complexity)\n",
    "\n",
    "    - Worst case time complexity (longest running time on any input of a certain size)\n",
    "    - Average case time complexity (average running time)\n",
    "        - How this generally works is that we assume that all possible inputs are equally likely, and then we take the expected value (same of mean) of the running time. (Deterministic algorithm with a probabilistic analysis)\n",
    "\n",
    "    - Randomized algorithms, we use *expected running time*\n",
    "\n",
    "### Divide and conquer *algorithm design technique*\n",
    "1. Divide problem into sub-problems\n",
    "2. Conquer sub-problems by solving them recursively\n",
    "3. Combine solutions to the sub problems\n",
    "\n",
    "###### Merge sort\n",
    "Example of a divide and conquer algorithm\n",
    "\n",
    "Input: An array of N numbers\n",
    "Divide: Two subarrays of size N/2\n",
    "Conquer: Sort each sub array recursively\n",
    "Combine: Combine the sub problems\n",
    "```python\n",
    "def Mergesort(A, p, r):\n",
    "    if p < r:\n",
    "        q = math.floor((p+r)/2)\n",
    "        Mergesort(A,p,q)\n",
    "        Mergesort(A, q+1, r)\n",
    "        Merge(A, p, q, r)\n",
    "        \n",
    "# Takes at most N comparisons\n",
    "def Merge(A, p, q, r):\n",
    "    pass\n",
    "    # Let's not worry about how this works\n",
    "        \n",
    "```\n",
    "\n",
    "###### Analysis of Divide & Conquer:\n",
    "\n",
    "Let's assume our algorithm has input size $n$ and creates $a$ subproblems of (equal, for now) size $n/b$, $a \\ge 1$, $b\\gt 1$\n",
    "\n",
    "$$T(n) = \\text{(worst case) running time}$$\n",
    "$$T(n) = a * T(n/b) + dividing(n) + combining(n)$$\n",
    "\n",
    "Has 3 methods of determining worst case running time:\n",
    "1. Recursion tree\n",
    "2. Substitution\n",
    "3. Master theorem\n",
    "\n",
    "###### For merge sort:\n",
    "$$T(1) = C_1$$\n",
    "$$T(n) = 2*T(n/2)+C_2*n$$\n",
    "\n",
    "Eventual solution is: $T(n) = O(n \\log n)$\n",
    "\n",
    "\n",
    "##### Recusing tree method of analysis:\n",
    "\"Unfold\" the recursion:\n",
    "(Assuming n=2^k)\n",
    "C*n -> C*n/2 + Cn/2 -> C*n/4 + C*n/4 + C*n/4 + C*n/4 -> ... -> C + C + ...\n",
    "\n",
    "We have $1+ \\log n$ levels, and each level takes C*n time (each level sums to C*n).\n",
    "\n",
    "$T(n) \\le C n (1+\\log n) = O(n\\log n)$\n",
    "\n",
    "##### Subsitution method of analysis\n",
    "1. Guess the form of the solution\n",
    "2. Verify guess by induction\n",
    "\n",
    "Basis: $P(1)$ is T (or $P(\\text{some other low value})$)\n",
    "\n",
    "Inductive step: $\\forall n (P(1)\\wedge ... \\wedge P(u)) \\rightarrow P(n+1) \\implies \\forall n P(n)$\n",
    "\n",
    "**Merge sort:**\n",
    "\n",
    "Assumption: T(n) <= cnlogn\n",
    "- Basis: T(1) = 1\n",
    "- T(n) = 2T(n/2) + n\n",
    "- T(n/2) <= C n/2 log(n/2) (assuming our assumption is right)\n",
    "\n",
    "`\n",
    "Basis: n=1:\n",
    "T(1) = 1\n",
    "n=2:\n",
    "T(2) = 4 <= C*2*log2 = 2c\n",
    "if c >= 2\n",
    "`\n",
    "\n",
    "**Incorrect application of the subtitution method (on merge sort):**\n",
    "\n",
    "Assumption: T(n) = O(n) $\\iff$ T(n) <= C n\n",
    "`\n",
    "T(n/2) <= C*n/2\n",
    "T(n) = 2*C*n/2 + n = cn+n = (c+1)n = O(n)\n",
    "`\n",
    "The error is that T(n) <= C n isn't T(n) <= (C+1) *n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Friday Jan 13\n",
    "\n",
    "### Master Theorem\n",
    "\n",
    "T(n) = O(1) if n <= c else: a*T(n/b)+f(n)\n",
    "\n",
    "##### Main idea of master theorem\n",
    "max(f(n), n^(log_b a)\n",
    "\n",
    "- $O(...) = $ Upper bound\n",
    "- $\\Omega (...) = $ Lower bound\n",
    "- $\\Theta (...) = $ Bounded on both sides\n",
    "\n",
    "\n",
    "##### Master Theorem\n",
    "\n",
    "- Case 1: If $f(n) = O(n^{log_b a - \\epsilon})$ for some $\\epsilon > 0$,\n",
    "    then $T(n) = \\Theta(n^{log_ba})$\n",
    "\n",
    "- Case 2: If $f(n) = \\Theta(n^{log_b a})$,\n",
    "    then $T(n) = \\Theta(f(n)\\cdot \\log n)$\n",
    "\n",
    "- Case 3: If $f(n) = \\Omega(n^{\\log_b a + \\epsilon})$ for some $\\epsilon > 0$ and we have the regularity condition $a \\cdot f(n/b) \\le c \\cdot f(n)$ for some $c < 1$ and $n \\ge n_0$,\n",
    "    then $T(n) = \\Theta(f(n))$\n",
    "\n",
    "- Else, we can't apply the Master Theorem\n",
    "\n",
    "##### Why does this work? (about the proof)\n",
    "(10 pages in the book)\n",
    "\n",
    "$$T(n) = a \\cdot T(n/b) + f(n)$$\n",
    "\n",
    "Recursion Tree:\n",
    "    T(n) = a \\cdot T(n/b) + f(n) = a(a(T(n/b) + f(n/b))+ f(n) = ...\n",
    "    \n",
    "    Written as a tree\n",
    "    f(n)\n",
    "    f(n/b) f(n/b) f(n/b)... (a times)\n",
    "    f(n/b^2) ... (a^2 times)\n",
    "    ...\n",
    "    1, 1, 1, ... (a^{log_b n} which is eqv. to: n^{log_b a}\n",
    "    \n",
    "    Has log_b(n) layers (n = b^k, so the problem has a size of 1)\n",
    "    \n",
    "- In Case 1, the bottom level dominates, which is $n^{\\log_b a}$\n",
    "- In Case 3, the top level ($f(n)$) dominates. (regularity condition catches bottom level, polynomially large catches the rest)\n",
    "- In Case 2, all the levels are roughly the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex 1:\n",
    "    T(n) = 9 T(n/3) + n\n",
    "    a=0, b=3, f(n) = n\n",
    "    \n",
    "    f(n) = n, also using: n^(log_3(9))) = n^2\n",
    "    \n",
    "    Case 1:\n",
    "       We can pick epsilon=1\n",
    "       n=O(n^(2-1)) = O(n), which equals f(n), so\n",
    "       T(n) = Theta(n^2)\n",
    "##### Ex 2:\n",
    "    T(n) = 1 T(2n/3) + 1\n",
    "    a = 1, b = 3/2, f(n) = 1\n",
    "    f(n) = 1, also using n^(log_3/2(1))\n",
    "    \n",
    "    Is Case 2:\n",
    "        T(n) = Theta(log n)\n",
    "        \n",
    "##### Ex 3:\n",
    "    T(n) = 3T(n/4) + nlogn\n",
    "    f(n) = n log n,\n",
    "    also using n^(log_4 (3)) (or, roughly n^0.8\n",
    "    \n",
    "    Is Case 3:\n",
    "        nlogn = Omega(n^(0.8+0.2or_similar))\n",
    "        Regularity condition: 3/4 â€¢ log(n/4) <= 3/4 n log n = 3/4 f(n), c = 3/4\n",
    "        T(n) = Theta(n log n)\n",
    "###### Ex 4:\n",
    "    T(n) = 2T(n/2) + n log n\n",
    "    f(n) = n log n, n^1\n",
    "    \n",
    "    NOT covered by Master Theorem (Case 3 is closest).\n",
    "    ( `n log n` isn't polynomially larger than `n^1`)\n",
    "    \n",
    "###### Ex 5: Merge sort:\n",
    "    T(n) = 2T(n/2) + n\n",
    "    f(n) = n, n^1\n",
    "    \n",
    "    Is Case 2:\n",
    "        T(n) = Theta(n log n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tuesday January 17\n",
    "In the book there are two more divide-and-conquer algorithms:\n",
    "\n",
    "1. **Maximum sub array problem:**\n",
    "    Given an array of $n$ numbers (may be negative), find the subarray that has the maximum sum. (Takes T(n) = 2T(n/2)+O(n), thus Theta(n log n)\n",
    "2. **Strassen Matrix multiplication algorithm:**\n",
    "    T(n) = 7T(n//2)+O(n^2), thus T(n)=Theta(n^2.7) (roughly)\n",
    "\n",
    "\n",
    "### Probabilistic analysis & randomized algorithms (Ch. 5)\n",
    "\n",
    "Random Variables are really a function from the sample space to real numbers.\n",
    "\n",
    "**Indicator random variable**: A binary (0, or 1) random variable. Traditionally 1 if event occurs, 0 if not.\n",
    "\n",
    "\n",
    "#### Interview problem\n",
    "```\n",
    "for i=1 to n\n",
    "    interview candidate[i]\n",
    "    if candidate[i] is better than previous best\n",
    "        best = i\n",
    "        hire candidate[i]\n",
    "```\n",
    "How many people do we hire?\n",
    "\n",
    "- Interview cost: $C_i$\n",
    "- Hiring cost: $C_h$\n",
    "\n",
    "Cost: $O(C_i n) + O(C_h\\cdot m)$ (where $m$ = number of people we actually hire/replace)\n",
    "Worst case $m = n$, if the interviewees come in increasing order.\n",
    "\n",
    "##### What is the average hiring cost ($m$)\n",
    "The average hiring cost is logarithmic ($O(\\log n)$ ), but let's show that:\n",
    "\n",
    "Assumption: Candidates in random order\n",
    "\n",
    "$X_i$ = 1 if we hire candidate i, 0 otherwise.\n",
    "\n",
    "$\\Sigma E(X_i) = \\Sigma(\\text{Probability candidate i is hired}) $\n",
    "Probability candidate i is hired = $1/i$\n",
    "\n",
    "$\\Sigma E(X_i) = \\Sigma(1/i) $ = Harmonic sequence ($H_n$) = $\\ln(n) + O(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday January 19th\n",
    "Probabilistic analysis & randomized algorithms cont.\n",
    "\n",
    "### Birthday Paradox\n",
    "K people in a room.\n",
    "When do we expect to have 2 people with the same birthday?\n",
    "\n",
    "Assumption: Birthdays are uniformly random, 365 days/year.\n",
    "\n",
    "Worst case: 366 people\n",
    "\n",
    "Expected:\n",
    "\n",
    "$k= O(sqrt(n)) \\approx 28$\n",
    "\n",
    "X= # of pairs of people born on the same date.\n",
    "\n",
    "Goal: $E(X) \\ge 1$\n",
    "\n",
    "$X_{ij}$ `= i and j have same birthday ? 1 : 0;`\n",
    "\n",
    "$E(X) = E(\\Sigma X_{ij}) = \\Sigma (E(X_{ij})) = \\Sigma (Pr(\\text{i and j ave same birthday}) = \\text{k choose 2} \\cdot 1/n = k(k-1)/(2n)$\n",
    "\n",
    "$$k(k-1)/(2n) \\ge 1$$\n",
    "$$ k(k-1) \\ge 2n$$\n",
    "....\n",
    "\n",
    "E(1) = 0/365, E(2) = 1/365, E(3) = E(2) + 2/365\n",
    "\n",
    "E(k) = E(k-1)+(k-1)/365\n",
    "\n",
    "### Formula satisfiability problem\n",
    "Note: this is NP complete.\n",
    "\n",
    "SAT\n",
    "\n",
    "We have a boolean formula using logical operators.\n",
    "\n",
    "Is there a satisfying truth assignment?\n",
    "\n",
    "CNF SAT (Three conjunctive normal form) = simplified transformation of boolean formula. = Conjunction of clauses, each of which are a disjunction of 3 different boolean variables.\n",
    "\n",
    "##### But there's a simple randomized algorithm that works pretty well!\n",
    "Expected number of clauses satisfied ($\\ge 7/8$)\n",
    "\n",
    "- Random truth assignment (each variable is true 0.5 of the time)\n",
    "- X = # of clauses satisfied ($E(X)=7/8 k$)\n",
    "- $X_i$ = 1 if clause is satisfied\n",
    "- $\\Sigma(Pr($Clause i is satisfied$)$\n",
    "- Each clause has an expected value of 7/8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heaps and heap sort\n",
    "- Optimal: $O(n\\log n)$\n",
    "- In place sort\n",
    "- C uses a combination of this and quicksort\n",
    "\n",
    "Using a (binary) heap. (Almost full binary tree, depth = O(log n))\n",
    "\n",
    "[root, child1, child2, child11, child12, child21, child 22...]\n",
    "\n",
    "```python\n",
    "# NOTE: may not actually run\n",
    "\n",
    "def parent(i):\n",
    "    return int(i/2) # int() floors\n",
    "def left(i):\n",
    "    return i*2\n",
    "def right(i):\n",
    "    return 2*i+1\n",
    "\n",
    "# Makes sure location i is correct relative to its children\n",
    "# O(log n)\n",
    "def maxHeapify(heap, i, heap_size=None):\n",
    "    if not heap_size:\n",
    "        heap_size = len(heap)\n",
    "        \n",
    "    left_child = heap[left(i)-1] if not left(i) > heap_size else float(\"-inf\")\n",
    "    right_child = heap[right(i)-1] if not right(i) > heap_size else float(\"-inf\")\n",
    "    parent = heap[i-1]\n",
    "    if parent >= max(left_child, right_child):\n",
    "        return heap\n",
    "    elif left_child > right_child:\n",
    "        heap[left(i)-1] = parent\n",
    "        heap[i-1] = left_child\n",
    "        return maxHeapify(heap, left(i))\n",
    "    else:\n",
    "        heap[right(i)-1] = parent\n",
    "        heap[i-1] = right_child\n",
    "        return maxHeapify(heap, right(i))\n",
    "\n",
    "# Makes a heap\n",
    "# O(n)\n",
    "def buildMaxHeap(llist):\n",
    "    heap = llist\n",
    "    \n",
    "    for i in range(len(heap)//2, 1, -1):\n",
    "        heap = maxHeapify(heap, i)\n",
    "    return heap\n",
    "# We'd assume this takes O(n log n), but:\n",
    "# => the depth of the heap being maxHeapified isn't always log(n)\n",
    "# => At any given height (set of values of i), maxHeapify takes O(height)\n",
    "# The number of leaves on any binary tree <= n/2, the number at height 1 is <= n/4.\n",
    "# At height h, there are <= n/(2^(h+1)) nodes\n",
    "# This means O(0)*n/2 + O(1)*n/4 + O(3)*n/8...\n",
    "\n",
    "# O(n log n)\n",
    "def heapSort(llist):\n",
    "    # O(n)\n",
    "    heap = buildMaxHeap(llist)\n",
    "    \n",
    "    for i in range(len(heap), 1, -1): # Do log(n) operation n times\n",
    "        heap[0], heap[i-1] = heap[i-1], heap[0]\n",
    "        heap = maxHeapify(heap, 0, heap_size=i)\n",
    "    \n",
    "    return heap\n",
    "```\n",
    "Build max heap discussion cont.:\n",
    "Runtime = $\\Sigma_{h=0,h\\le \\log(n)}(O(h)*n/2^{h+1}) = O(n)*\\Sigma(h/2^{h+1}) = O(n) * \\text{well known converging series} = O(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday Jan 20\n",
    "\n",
    "#### Priority queue:\n",
    "A data structure set S of objects each with a key:\n",
    "\n",
    "Supports 4 options:\n",
    "\n",
    "1. Maximum(S)\n",
    "2. Extract-Max(S)\n",
    "3. Insert(S, x)\n",
    "4. Increase-key(S,x,k) (raise priority)\n",
    "\n",
    "We can use a **max-binary-heap** for this data structure:\n",
    "```python\n",
    "# This is in **pseudocode**\n",
    "\n",
    "# O(1)\n",
    "def maximum(heap):\n",
    "    return heap[0]\n",
    "\n",
    "# O(log(n))\n",
    "def extract_max(heap):\n",
    "    max = heap[0]\n",
    "    heap[0] = heap.last # Last may or may not be smallest\n",
    "    heap.size--\n",
    "    maxHeapify(heap, 0)\n",
    "    return max\n",
    "# O(log(n))\n",
    "def insert(heap, x):\n",
    "    heap.size++\n",
    "    heap.last = x\n",
    "    increase_key(heap, x, k)\n",
    "# O(log(n))\n",
    "def increase_key(heap, x, k):\n",
    "    # Find x\n",
    "    # Magic! (don't know how this would be fast)\n",
    "    # You could use hashmap magic or x could be a reference to a node of a linked tree.\n",
    "    \n",
    "    x.priority = k\n",
    "    # Floating up:\n",
    "    # O(log(n))\n",
    "    while x.parent && x.parent < x:\n",
    "       heap[x.pos], heap[x.parent.pos] = heap[x.parent.pos], heap[x.pos]\n",
    "\n",
    "# My own idea... not part of priority queue contract\n",
    "def decrease_key(heap, x, k):\n",
    "    x.priority = k\n",
    "    maxHeapify(heap, x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# Monday January 23\n",
    "\n",
    "### Quicksort:\n",
    "A[p...r]\n",
    "\n",
    "1. \"Partition around\" the pivot element\n",
    "    - A[p...q-1 < A[q] < A[q+1...r]\n",
    "2. Recursively sort the two subarrays\n",
    "3. Combining is trivial.\n",
    "\n",
    "```python\n",
    "def Quicksort(A, p, r):\n",
    "    if p < r:\n",
    "        q = Partition(A, p, r)\n",
    "        Quicksort(A, p, q-1)\n",
    "        Quicksort(A,q+1, r)\n",
    "def Partition(A, p, r):\n",
    "    # A becomes: [<x..., >x..., undecided..., x]\n",
    "    # Pivot element is at A[r-1]\n",
    "    i=0\n",
    "    for j in range(p, r-1):\n",
    "        if A[j] < A[r-1]:\n",
    "            A[i], A[j] = A[j], A[i]\n",
    "            i+=1\n",
    "    A[i+1], A[r-1] = A[r-1], A[i+1]\n",
    "            \n",
    "\n",
    "```\n",
    "##### Analysis\n",
    "- Worst case: Every pivot element is a minimum or maximum of the subarray.\n",
    "    This can happen if the array is already sorted.\n",
    "    $$T(n) = T(1)+T(n-1)+cn = O(n^2)$$\n",
    "- Best case: Pivot is centered\n",
    "    $$T(n) = 2T(n/2)+cn = O(n \\log n)$$\n",
    "- Okay case: Pivot is off center.\n",
    "    $$T(n) = T(n/10) + T(9n/10) + cn = O(n \\log n) $$ (Use recursion tree method: depth is $log_{10/9}$ width at each level: $cn$\n",
    "    \n",
    "##### Analysis of randomized version:\n",
    "Showing $E(X) = O(n\\log n)$\n",
    "\n",
    "* We bound the total # of comparisons $Z_{ij} = {Z_i < ... Z_j}$\n",
    "* When do we compare $Z_i$ and $Z_j$?\n",
    "* We perform comparisons only when one of the elements is a pivot element.\n",
    "    * We can *never* compare the same two numbers twice.\n",
    "* $X_{ij}$ = 1 if $Z_i$ and $Z_j$ are compared.\n",
    "* $X = \\sum_{n-1} \\sum_n X_{ij}$\n",
    "* $E(X)=E(\\sum_{n-1} \\sum_n X_{ij}) = \\sum_{n-1} \\sum_n E(X_{ij})$\n",
    "* Either $Z_i$ or $Z_j$ is a pivot element.\n",
    "    * In the interval $Z_{ij}$\n",
    "        * If $Z_i < \\text{pivot element} < Z_j$, then they will never be compared.\n",
    "        * Thus $X_{ij}$ = Probability that $Z_i$ or $Z_j$ is the 1st pivot element from $Z_{ij}$, which is $\\frac{2}{\\text{interval length}} = \\frac{2}{j-i+1}$\n",
    "* $\\sum_{i=1...n-1} \\sum_{k=1, n-i} \\frac{2}{k+1}$ = $n* \\text{Harmonic sequence} = O(n\\log n)$\n",
    "\n",
    "If we can find the median quickly (which we can do in $O(n)$), then we can make the worst case $O(n \\log n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting cannot be improved beyond $O(n \\log n)$\n",
    "For any comparison-based sorting algorithm, it must take $\\ge n\\log n$ steps in the worst case. $\\Omega(n \\log n)$\n",
    "\n",
    "1. Decision tree method: (It's very rare that the decision tree method will give the lowest bound)\n",
    "2. Adversary argument: (much better) \"Adversary\" trys to make your algorithm look as bad as possible.\n",
    "\n",
    "#### Binary search tree for comparison based sorting\n",
    "Sorting algorithms are like Binary search trees. Each comparison gives us two options, we can build each of these possibilities as a binary tree, where leaves are when the algorithm finishes, which should be contain all the $n!$ unique permutations (or have repeats - but that's inefficient.)\n",
    "\n",
    "So, we have at least $n!$ leaves. Each execution of the algorithm follows a path from the root to a leaf.\n",
    "\n",
    "$$n! \\le \\text{# of leaves} \\le 2^{\\text{height of tree}} = 2^{\\text{worst case running time}}$$\n",
    "\n",
    "$$ n! \\le 2^{\\text{worst case running time}} $$\n",
    "\n",
    "$$ \\log_2 n! \\le \\text{worst case running time}$$\n",
    "\n",
    "It's fairly obvious that $n! = n * (n-1) * ... (n/2) * (n/2 - 1)... 2 * 1 \\gt (n/2)^{n/2}$, thus:\n",
    "    $$ \\log_2 (n/2)^{n/2} \\lt \\log_2 n! \\le \\text{worst case running time}$$\n",
    "    $$ n/2 * \\log_2 (n/2) \\lt \\text{worst case running time}$$\n",
    "    $$ \\Omega(n \\log_2 n) = \\text{worst case running time}$$\n",
    "\n",
    "A tree with $n!$ leaves *must* have height of $n \\log_2 n$ or more.\n",
    "\n",
    "Merge sort and heap sort are optimal (at least as far as $O$ notation goes)\n",
    "\n",
    "###### General equation for (binary) search tree problem:\n",
    "$$X \\le \\text{# of possible answers} \\le 2^h$$\n",
    "$$h \\ge log X$$\n",
    "$$h = \\text{worst case running time, also the tree height}$$\n",
    "This is usually a pretty weak lower bound.\n",
    "\n",
    "### Exceptions - non-comparison based sorting algorithm with $O(n)$\n",
    "##### Counting sort\n",
    "Assume that all numbers come from the range $0,1,...k$ where $k = O(n)$\n",
    "Algorithm runs in $O(n+k)$.\n",
    "\n",
    "Doing this *stable* (equal elements are left in the same relative position).\n",
    "\n",
    "```python\n",
    "def count_sort(input, max):\n",
    "    C = [0]*max # Counts or indexes\n",
    "    output = [-1]*len(input)\n",
    "    \n",
    "    # Get the counts\n",
    "    for i in range(len(input)):\n",
    "        C[input[i]] += 1\n",
    "    \n",
    "    # Sum the counts\n",
    "    # (any item with index i will be at or before output[C[i]])\n",
    "    for i in range(1, max):\n",
    "        C[i] = C[i] + C[i-1]\n",
    "        \n",
    "    # Put elements into the output array\n",
    "    # Start from back to make it stable\n",
    "    for i in range(len(input), -1, -1): # i = n downto 0\n",
    "        output[C[input[i]]] = input[i]\n",
    "        C[input[i]] += -1\n",
    "    return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection problem: Find the ith smallest element (or other statistic)\n",
    "Special cases:\n",
    "- $i=1$ minimum\n",
    "- $i=n$ maximum\n",
    "- $i=\\frac{n+1}/2$ median. Note: if $n$ is even, we probably want to find two medians.\n",
    "\n",
    "Can be done in $O(n)$!\n",
    "\n",
    "Finding the **Maximum** is \"exactly typed\" with $n-1$ comparisons.\n",
    "\n",
    "###### (simple) Adversary argument for finding the maximum\n",
    "Each player who is *not* the max must be compared and be smaller than at least one element, thus at least $n-1$ matches (e.g. comparing the max against each element, or something else similar).\n",
    "\n",
    "We call the way of thinking about matches this way as the **Tournament method**\n",
    "\n",
    "Suppose that there is an algorithm such that there are two elements $x$ and $y$ who never lost.\n",
    "\n",
    "Our algorithm must declare one of them (say $x$) as the winner.\n",
    "\n",
    "But if our adversary picks an input such that $y$ is the maximum, then the algorithm would be wrong!\n",
    "\n",
    "Thus each non-maximum should loose a comparison and there should be at least $n-1$ comparisons.\n",
    "\n",
    "### Simultaneous minimum and maximum\n",
    "Can obviously do this in $2(n-1)$, but we can do better.\n",
    "\n",
    "We can do it in $3/2 *(n-1)$\n",
    "\n",
    "We compare pairs to each other, then compare the larger of the two to max, the smaller to min.\n",
    "\n",
    "- For $n$ is odd, we have $3\\left \\lfloor{n/2}\\right \\rfloor$ (start with A[0] as both max and min)\n",
    "- For $n$ is even, we have $3n/2 -2$ (start with max(A[0], A[1]) and min(A[0], A[1])\n",
    "\n",
    "```python\n",
    "def min_max(A):\n",
    "    min = A[0]\n",
    "    max = A[0]\n",
    "    for i in range(1, len(A)/2):\n",
    "        A[i*2-1] = \n",
    "        A[i*2] = \n",
    "```\n",
    "\n",
    "#### Proof that this is the best running time\n",
    "Let's create 4 sets:\n",
    "$(B, W, L, O)$\n",
    "\n",
    "- $B$ - beginners\n",
    "- $W$ - winners, no losses, some wins\n",
    "- $L$ - losers, some losses, no wins\n",
    "- $O$ - others, some wins and losses\n",
    "\n",
    "Initially: $(n, 0, 0, 0)$\n",
    "\n",
    "At the end: $(0, 1, 1, n-2)$\n",
    "\n",
    "###### Adversary's goals:\n",
    "1. Nothing should go directly from $B$ to $O$. (this slows things down)\n",
    "2. From $W$ and $L$, they go to $O$ one by one.\n",
    "\n",
    "Suppose the Adversary achieves this goal.\n",
    "\n",
    "We need at least $\\left \\lceil{n/2}\\right \\rceil$ comparisons to empty $B$\n",
    "We need $n-2$ comparisons to empty $W$ and $L$.\n",
    "\n",
    "x:y | $(B,W,L,O)$\n",
    "----|---------------------\n",
    "B:B | $(B-2, W+1, L+1, O)$\n",
    "B:W | $(B-1, W, L+1, O)$\n",
    "    | $(B-1, W, L, O+1)$ - adversary eliminates\n",
    "B:L | $(B-1, W+1, L, O)$\n",
    "    | $(B-1, W, L, O+1)$ - adversary eliminates\n",
    "B:O | $(B-1, W+1, L, O)$\n",
    "    | $(B-1, W, L+1, O)$\n",
    "W:W | $(B, W-1, L, O+1)$\n",
    "W:L | $(B, W, L, O)$\n",
    "    | $(B, W-1, L-1, O+2)$ - adversary eliminates\n",
    "W:O | $(B, W, L, O)$ - adversary prefers\n",
    "    | $(B, W-1, L, O+1)$\n",
    "L:L | $(B, W, L-1, O+1)$\n",
    "L:O | $(B, W, L, O)$ -adversary prefers\n",
    "    | $(B, W, L-1, O+1)$\n",
    "O:O | $(B, W, L, O)$\n",
    "\n",
    "The adversary can control the $B$ set, so it can control any comparison with it, but it is less obvious how it can control the comparisons with just the other 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# A=Array\n",
    "# p=partition start\n",
    "# r=partition end\n",
    "# i=number of elements smaller than the result (e.g. 0 for min(A))\n",
    "def Randomizedselect(A, p, r, i):\n",
    "    q = RandomizedPartition(A, p, r)\n",
    "    k = q-p+1 # Rank\n",
    "    if i==k:\n",
    "        return A[q]\n",
    "    elif i < k:\n",
    "        return RandomizedSelect(A, p, q-1, i)\n",
    "    else:\n",
    "        return RandomizedSelect(A, q+1, r, i-k)\n",
    "```\n",
    "Has an expected running time of $O(n)$, but a worst case running time of $O(n^2)$\n",
    "\n",
    "1. Divide into groups of 5 elements\n",
    "    - Why 5? It's odd, so we can find the median.\n",
    "2. Find the median of each group $O(n) * O(5)$\n",
    "3. Find the median of the medians ($x$) by repeating step 2\n",
    "    - $O(n/5)$\n",
    "4. Partition around this median of medians $k$ = rank of $x$\n",
    "5. if $i=k$, return $x$\n",
    "   if $i<k$, Recursively find ith on the low side\n",
    "   if $i>k$, recursively find $(i-k)^{th}$ on the high side\n",
    "\n",
    "This guarantees a fairly even split and thus $O(n)$ running time.\n",
    "The split is fairly even because $x$ cannot be in the highest or lowest quartile.\n",
    "$x$ is lower than half of the medians, and thus is lower than 3/5 of their elements. $x$ is smaller than $3(0.5 * \\frac{n}{5}-2) = 0.3n - 6$ (-2 is beccause the 1st group may not contain all 5 elements.)\n",
    "\n",
    "$T(n) \\le T(0.7n+6) + T(n/5) + an$\n",
    "\n",
    "We can use the **substitution method** to find $T(n) \\le cn$ if $c$ is large enough compared to $a$\n",
    "\n",
    "Assume $T(n) \\le cn$.\n",
    "\n",
    "$$T(n) = c\\cdot 0.7n+6 + c \\cdot n/5 + an \\le cn$$\n",
    "$$\\frac{9cn}{10}+an+6c \\le c\\cdot n$$\n",
    "$$ an + 6c \\le \\frac{c}{10} n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## January 30\n",
    "# Binary Search Trees\n",
    "- Can perform an `in-order-tree-walk` to get a sorted list\n",
    "```python\n",
    "def inOrderTreeWalk(root):\n",
    "    if root == None:\n",
    "        return []\n",
    "    return inOrderTreeWalk(root.left) + [root.key] + inOrderTreeWalk(root.right)\n",
    "```\n",
    "\n",
    "- Finding an item in the tree is $O(\\text{height})$\n",
    "\n",
    "```python\n",
    "def TreeSearch(key, root):\n",
    "    if root == None:\n",
    "        return None # key is not in the tree\n",
    "    if root.key == key:\n",
    "        return root\n",
    "    elif root.key > key:\n",
    "        return TreeSearch(key, root.right)\n",
    "    else:\n",
    "        return TreeSearch(key, root.left)\n",
    "        \n",
    "def TreeInsert(key, root):\n",
    "    child = None\n",
    "    if root.key > key:\n",
    "        child = root.right\n",
    "    else:\n",
    "        child = root.left\n",
    "    if child != None:\n",
    "        TreeInsert(key, child)\n",
    "    else:\n",
    "        if root.key > key:\n",
    "            root.right = Node(key, parent=root)\n",
    "        else:\n",
    "            root.left = Node(key, parent=root)\n",
    "            \n",
    "def TreeMinimum(root):\n",
    "    while root.left != None:\n",
    "        root = root.left\n",
    "    return root.key\n",
    "```\n",
    "\n",
    "Removing from a tree is a bit trickier.\n",
    "```python\n",
    "def TreeSuccessor(root):\n",
    "    if root.right == None:\n",
    "        # Go up on the left until the 1st right turn\n",
    "        y = root.parent\n",
    "        while y != None and root == y.right:\n",
    "            root = y\n",
    "            y = y.parent\n",
    "        return y \n",
    "    else:\n",
    "        return TreeMinimum(root.right)\n",
    "\n",
    "def TreeRemove(root):\n",
    "    if root.left == None:\n",
    "        root.parent.appropriateChild = root.right\n",
    "        if root.right != None:\n",
    "            root.right.parent = root.parent\n",
    "    elif root.right == None:\n",
    "        root.parent.appropriateChild = root.left\n",
    "        root.left.parent = root.parent\n",
    "    else: # We have 2 children\n",
    "        successor = TreeSuccessor(root) # Successor has at most one child because root has two children\n",
    "        TreeRemove(successor) # This runs in O(1) time because successor has no left child\n",
    "        #successor.parent.appropriateChild = successor.right\n",
    "        #if successor.right: successor.right.parent = successor.parent\n",
    "        root.parent.appropriateChild = successor\n",
    "        successor.parent = root.parent\n",
    "        successor.left = root.left\n",
    "        successor.right = root.right\n",
    "```\n",
    "\n",
    "The height is not necessarily $O(log(n))$ - e.g. if the keys come in sorted order.\n",
    "\n",
    "If the keys are inserted (with no deletions) in random order, $E(\\text{height}) = O(\\log(n))$.\n",
    "\n",
    "This takes a while to show, but seems straightforward, it proves easiest to use the *exponential height* $Y_n = 2^{X_n}$ and $Z_{n,i}$ `=1 if the rank of the root is i`. $E(Z_{n,i}) = 1/n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy algorithms\n",
    "### Activity selection problem\n",
    "Set of activities $a_1, a_2...$ are competing for a resource for each activity $a_i$:\n",
    "\n",
    "- $s_i$ = starting time \n",
    "- $f_i$ = finishing time\n",
    "- $a_i = [s_i, f_i)$\n",
    "\n",
    "Activities $a_i$ and $a_j$ are compatible if their times don't overlap.\n",
    "\n",
    "**Goal**: Find a maximum set of mutually compatible set of activities.\n",
    "\n",
    "\n",
    "\n",
    "1. Sort activities by finishing time! ($O(n \\log n)$)\n",
    "2. Greedy choice: We select 1st the activity that finishes 1st ($a_1$)\n",
    "3. remove activities that start before $f_1$\n",
    "4. repeat as necessary\n",
    "\n",
    "###### Claim for greedy choice to work:\n",
    "Let $a_m$ be the activity that finishes 1st in $S_k$ $a_m$ is part of an optimal solution for $S_k$\n",
    "\n",
    "\n",
    "Let $A_k$ be an optimal solution for $S_k$.\n",
    "\n",
    "- If $a_m \\in A_k$ - our assumption is fine\n",
    "- Else $a_m \\not\\in A_k$:\n",
    "    - We can replace $a_j$ with $a_m$ where $a_j$ is the element in $A_k$ that finishes first.\n",
    "        - $a_m$ *must* finish before $a_j$, so $A_k - {a_j} + {a_m}$ is still compatible.\n",
    "        - $A_k - {a_j} + {a_m}$ is just as optimal as $A_k$.\n",
    "\n",
    "Thus the greedy choice provides a globally optimal solution.\n",
    "\n",
    "```python\n",
    "# Actually psuedocode\n",
    "\n",
    "activities.sort_by(\"finishing_time\") # O(nlogn)\n",
    "\n",
    "finishing_time = 0\n",
    "while not activities.empty(): # O(n^2)\n",
    "    finishing_time = activities.dequeue().finishing_time\n",
    "    activities = activities.filter(lambda x: x.starting_time > finishing_time)\n",
    "```\n",
    "Or, more efficiently:\n",
    "\n",
    "```python\n",
    "activities.sort_by(\"finishing_time\") # O(nlogn) - though we can probably do a linear time sort!\n",
    "\n",
    "finishing_time = 0\n",
    "while not activities.empty(): # O(n)\n",
    "    a = activities.dequeue()\n",
    "    if a.starting_time > finishing_time:\n",
    "        finishing_time = a.finishing_time\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amortized analysis\n",
    "\n",
    "Let's say we have a sequence of $n$ operations that can have very different running times.\n",
    "\n",
    "We want to average over $n$ operations.\n",
    "\n",
    "This is *very* different from average case analysis. (Amortized = average over operations, no probability. Average-case = average over all inputs)\n",
    "\n",
    "###### Multipop stack example\n",
    "3 operations:\n",
    "\n",
    "- Push(S, x) $O(1)$\n",
    "- Pop(S) $O(1)$\n",
    "- Multipop(S, k) (pops $min(|S|, k)$ elements. $O(k) \\le O(n-1) = O(n)$ or $O(1)$ depending on implementation\n",
    "\n",
    "###### Binary counter example\n",
    "Have $k$ bits, cost is number of bits we have to flip.\n",
    "\n",
    "We can consider the counter equal to $x=\\sum_{i=0...k-1} A[i]*2^i$\n",
    "\n",
    "So, if $k=4$,\n",
    "\n",
    "- 0 -> 1: 1 bit flipped\n",
    "- 1 -> 2: 2 bits flipped\n",
    "- etc. upt until 15 -> 0: 4 bits flipped.\n",
    "\n",
    "Worst case for one operation $O(nk)$.\n",
    "\n",
    "#### Aggregate method\n",
    "$$T(n) = \\text{total bound for the cost of the n operations}$$\n",
    "$$\\text{amortized cost (aggregate method)} \\le \\frac{T(n)}{n}$$\n",
    "\n",
    "###### Multipop stack example\n",
    "If we have $n$ operations, which might be multipop, $T(n) = O(n*n)=O(n^2)$. But we can do better.\n",
    "\n",
    "Let's look at the total number of pops: we can have $n-1$ pops ($\\le$ number of pushes $\\le n$)\n",
    "$$ T(n) \\le 2n = O(n)$$\n",
    "\n",
    "$$\\text{amortized cost } \\le \\frac{T(n)}{n} = \\frac{O(n)}{n} = O(1)$$\n",
    "\n",
    "###### Binary counter example\n",
    "\n",
    "We have to flip the last bit $n$ times, 2nd bit $n/2$, 3rd $n/4$... etc.\n",
    "So the total flips is:\n",
    "$$T(n)\\le \\sum_{i=0...k-1} \\frac{n}{2^i} \\le n \\sum_{i=0...\\infty} = 2n$$\n",
    "\n",
    "$$\\text{amortized cost } \\le \\frac{T(n)}{n} = \\frac{O(2n)}{n} = O(2)$$\n",
    "\n",
    "\n",
    "#### Accounting method\n",
    "\n",
    "- $c_i$ = actual cost of operation i.\n",
    "- $\\bar {c_i}$ = amortized cost.\n",
    "    - If we guess too high, we can consider the extra as credit for later operations. $\\sum \\bar c_i - \\sum c_i = \\text{credit} \\ge 0$\n",
    "    - We *need* to make sure $\\text{credit} \\ge 0$\n",
    "\n",
    "We have different amortized costs for different operations.\n",
    "\n",
    "###### Multipop stack example\n",
    "If we overcharge for the push (pretend it costs $O(2)$), we can pop freely (assuming we don't underflow our stack).\n",
    "\n",
    "Now we need to show $\\text{credit} \\ge 0$. We put 1 operation in credit for each element in the stack, and the only operations we use to remove elements cost as much as the number of elements they remove, so because $\\text{# of plates} \\ge 0$, $\\text{credit} \\ge 0$. We have to assume that we never underflow the stack, however.\n",
    "\n",
    "Amortized Cost:\n",
    "\n",
    "- Push: $2$\n",
    "- Pop: $0$\n",
    "- Multipop: $0$\n",
    "\n",
    "###### Binary counter example\n",
    "We can charge each operation for the number of 1s in the counter.\n",
    "\n",
    "**Showing** $\\sum \\bar c_i - \\sum c_i = \\text{credit} \\ge 0$:\n",
    "\n",
    "$\\sum \\bar c_i - \\sum c_i$ is the number of ones, so $\\sum c_i \\le \\sum \\bar c_i \\le 2n$\n",
    "\n",
    "#### Potential method\n",
    "We have a state associated with each possible configuration, and we need a function $\\Phi$ that gives us the potential of the state such that: $$\\bar c_i = c_i + \\Phi(\\text{state}_{i})-\\Phi(\\text{state}_{i-1})$$\n",
    "\n",
    "##### Multipop example\n",
    "$\\Phi$ = # of elements in the stack\n",
    "\n",
    "- Push $\\bar c_i = 1 + 1 = 2$\n",
    "- Pop $\\bar c_i = 1 + (-1) = 0$\n",
    "- Multipop $\\bar c_i = k+(-k) = 0$\n",
    "\n",
    "##### Binary counter example\n",
    "$\\Phi$ = # of 1s in the counter, which gives us the same result as the Accounting method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "- Pay attention to subproblems\n",
    "- Use a table to avoid recomputation\n",
    "- The subproblems make a `directed acyclic graph`\n",
    "\n",
    "\n",
    "### Longest Common Subsequence\n",
    "```python\n",
    "def is_subseq(subseq, y):\n",
    "    i=0\n",
    "    for letter in subseq:\n",
    "        while letter != y[i]:\n",
    "            i = i+1\n",
    "            if len(y) <= i:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Brute force method:\n",
    "import itertools\n",
    "def dumb_lcs(x, y):\n",
    "    max_subseq = \"\"\n",
    "    # for each subsequence of x\n",
    "    for length in range(len(x)):\n",
    "        for subseq in itertools.combinations(iterable, r):\n",
    "            if len(max_subseq) < len(subseq) and is_subseq(subseq, y):\n",
    "                max_subseq = subseq\n",
    "\n",
    "# Naive, but reasonable method\n",
    "def naive_lcs(x,y):\n",
    "    if (not x) or (not y):\n",
    "        return \"\"\n",
    "    else:\n",
    "        if x[0] == y[0]:\n",
    "            return x[0] + naive_lcs(x[1:], y[1:])\n",
    "        else:\n",
    "            tmp1 = naive_lcs(x, y[1:])\n",
    "            tmp2 = naive_lcs(x[1:], y)\n",
    "            return tmp1 if len(tmp1) > len(tmp2) else tmp2\n",
    "import numpy as np\n",
    "def lcs(x,y):\n",
    "    #make_lcs_len_subseq\n",
    "    table = np.zeros((len(x)+1,len(y)+1))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            if x[i] == y[j]:\n",
    "                table[i+1, j+1] = table[i,j] + 1\n",
    "            else:\n",
    "                table[i+1, j+1] = max(table[i,j+1], table[i+1, j])\n",
    "    # trace back lcs subseq\n",
    "    subseq = \"\"\n",
    "    i = len(x)\n",
    "    j = len(y)\n",
    "    while table[i,j] != 0:\n",
    "        if x[i-1] == y[j-1]: #table[i,j] == table[i-1, j-1]\n",
    "            subseq = x[i-1] + subseq\n",
    "            i += -1\n",
    "            j += -1\n",
    "        elif table[i-1, j] == table[i,j]:\n",
    "            i += -1\n",
    "        elif table[i, j-1] == table[i,j]:\n",
    "            j += -1\n",
    "        else:\n",
    "            # shouldn't get here\n",
    "            print('error')\n",
    "    return subseq\n",
    "\n",
    "lcs(\"spanking\", \"amputation\") == \"pain\" and lcs('abcuvxy', 'bcwxyz') == 'bcxy'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs: Minimum Spanning tree:\n",
    "Have a graph $G=(V, E)$, connected, undirected, and weighted with $w(e)$.\n",
    "\n",
    "$T$ spanning tree where $w(T)=\\sum_{e\\in T} w(e)$.\n",
    "\n",
    "**Goal:** Find a MST $T$ where $w(T)$ is minimum.\n",
    "\n",
    "#### Generic greedy algorithm: (both Kruskal's and Prim's algorithms)\n",
    "$$O(E \\cdot \\log V)$$\n",
    "\n",
    "We'll need to define a few terms. A *Cut* is a split of the graph's vertexes into two groups, and a crossing edge is one that goes from one of the groups or another.\n",
    "The cut $C=(S, V-S)$ *respects* $A$ (a set of edges) if none of the edges of $A$ is a crossing edge.\n",
    "\n",
    "```python\n",
    "# Pseudocode\n",
    "\n",
    "A = {} # Set of edges. ALWAYS a part of some spanning tree\n",
    "while A is not a MST: # len(A) + 1 = len(vertices)\n",
    "    C = select_cut(respecting=A)\n",
    "    A += C.crossing_edges().lightest()\n",
    "\n",
    "def select_cut_prims(respecting={}):\n",
    "    if respecting == {}:\n",
    "        respecting = {vertices[0]}\n",
    "    \n",
    "    q = minQueue(vertices[0].adjacent, distance_from_A)\n",
    "    u=extract_min(q)\n",
    "    a.add(u)\n",
    "    q.add(u.adjacent)\n",
    "    \n",
    "\n",
    "def select_cut_kruskals(respecting={}):\n",
    "    # Graph is given as a neighborhood list\n",
    "    if !sorted_e:\n",
    "        sorted_e = edges.sort_by('weight') # This is the majority of the work O(ElogE) = O(ElogV)\n",
    "        \n",
    "    connected_components = vertices.map(lambda v: [v]) # don't use \n",
    "    \n",
    "    while connected_components.any(contains_both_ends(sorted_e[0])):\n",
    "        sorted_e = sorted_e[1:]\n",
    "    \n",
    "    connected_components.filter(contains_an_end(sorted_e[0])).combine()\n",
    "    sorted_e = sorted_e[1:]\n",
    "\n",
    "\n",
    "# Actual reasonable version of the algorithm:\n",
    "def primsMST(vertices): # Not quite prim's - Prim's keeps a min queue of vertices+weights, not edges\n",
    "    mst = []\n",
    "    verts = [vertices[0]]\n",
    "    q = minQueue(vertices[0].edges, sort_by_weight)\n",
    "    while len(verts) != len(vertices):\n",
    "        u = q.minPop()\n",
    "        if u.end_two not in verts:\n",
    "            mst = mst + [u]\n",
    "            verts = verts + [u.end_two]\n",
    "            q.add(u.end_two.edges)\n",
    "         \n",
    "def primsMST(vertices):\n",
    "    mst = []\n",
    "    verts = [vertices[0]]\n",
    "    q = minQueue(vertices, weights=+infinity)\n",
    "    while len(verts) != len(vertices):\n",
    "        u = q.minPop() # Runs V times, so O(V log V)\n",
    "        for edge in u.adjacent:\n",
    "            q.decreaseKey(edge.vertex, edge.weight) # Runs E times, so O(E logV)\n",
    "```\n",
    "##### Show that $A_{t=t+1} \\in \\text{some spanning tree}$ given $A_{t=0}$\n",
    "Let us have a spanning tree $T$ that $A$ is part of.\n",
    "\n",
    "Now we want to show that $A+(u,v)$ is part of some MST.\n",
    "\n",
    "We know that there is an edge $(x,y)\\in T$ where $(x,y)$ crosses any cut (that has non-empty sides).\n",
    "\n",
    "Let $T' = T-(x,y) + (u,v)$. Then $w(T') = w(T)$\n",
    "\n",
    "....\n",
    "\n",
    "$A$ is a forest (but not yet a spanning tree). Let's take one of the connected components ($C$).\n",
    "Let our cut be one of the connected components, and the rest of the graph. The lightest edge of this cut, $(u,v)$ is safe to add to $A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Shortest path (directed graph)\n",
    "$$\\text{Given Graph $G$, connected weighted, directed graph (as neighborhood list)}$$\n",
    "We want to minimize:\n",
    "$$w(\\text{path}) = \\sum^k_{i=1} w(v_{i-1}, v_i)$$\n",
    "$$\\delta(u, v) = \\min_P w(P)$$\n",
    "\n",
    "Goal: Find $\\delta(s,v) \\mid v \\in V$\n",
    "\n",
    "There may be some negative weight edges, but no negative weight cycles in G. (this means there's no cycles in the shortest path, and thus `len(shortest_path) <= len(vertices)-1`.\n",
    "\n",
    "Also, the sub-path of any shortest path is the shortest path between those vertices.\n",
    "\n",
    "### Bellman-Ford algorithm\n",
    "Slightly slower than Dijsktra, but detects negative weight cycles (and allows negative weights)\n",
    "#### is a relaxation method\n",
    "$v.d$ = current upper bound on $\\delta(s, v)$, it starts at infinity.\n",
    "\n",
    "```python\n",
    "# Pseudocode assumes:\n",
    "# w(vertex1, vertex2) = weight function\n",
    "# edges = [{ u: start vertex, v: end vertex },...]\n",
    "\n",
    "def Relax(u,v):\n",
    "    if u.d + (w(u,v)) < v.d: # if distance to u + weight(edge between u &v)) < distance to v\n",
    "        v.d = u.d + w(u,v)\n",
    "        v.predecessor = u # often v.pi= predecessor\n",
    "\n",
    "def BellmanFord(edges, start, end):\n",
    "\n",
    "    # relax every edge V-1 times\n",
    "    for i in range(len(vertices)-1):\n",
    "        for (u,v) in edges:\n",
    "            Relax(u, v)\n",
    "    \n",
    "    # check for negative weight cycles\n",
    "    for (u,v) in edges:\n",
    "        if u.d + w(u,v) < v.d:\n",
    "            throw \"Negative weight cycle detected\n",
    "    \n",
    "    # Create path\n",
    "    path = []\n",
    "    while path[0] != start:\n",
    "        path = [path[0].predecessor] + path\n",
    "    return path\n",
    "```\n",
    "\n",
    "##### Correctness of BF\n",
    "**Path relaxation Property**: If $P=(v_0, v_1, ... v_k)$ is a shortest path from $v_0=s$ to $v_k=v$, and we relax the edges $(v_0, v_1), (v_1, v_2), (v_2, v_3),... (v_{k-1}, v_k)$ in this order, then at the end $v.d = \\delta(s,v)$.\n",
    "This still holds if we perform other relaxations intermixed.\n",
    "\n",
    "###### Detecting negative weight cycles\n",
    "If there is a negative weight cycle, we should be able to detect it:\n",
    "$$\\exists \\text{ a cycle } C(v_0, v_1, ... v_{k-1}, v_0) \\mid \\sum_{i=1}^k w(v_i, v_{i-1})$$\n",
    "\n",
    "If there is a negative weight cycle, then:\n",
    "$$\\sum v_i .d \\le \\sum v_{i-1}.d +\\sum w(v_{i-1}, v_i)$$\n",
    "\n",
    "### Dijkstra\n",
    "Can think of Dijkstra's algorithm as like Prim's algorithm.\n",
    "\n",
    "We maintain a set $S$ for which we know the shortest path, and we maintain a priority queue of vertices to relax.\n",
    "\n",
    "Takes $O(E \\log V)$, so $O(n^2 \\log n)$\n",
    "```python\n",
    "def dijkstra():\n",
    "    q = PriorityQueue(start)\n",
    "    S = {start} # Set of vertices we know the shortest path of\n",
    "    while not q.empty():\n",
    "        u = q.extract_min()\n",
    "        S += u\n",
    "        for vertex in u.neighbors:\n",
    "            Relax(u,v) # relax also has to do q.reduce_key(v, ...) and v.d = ...\n",
    "\n",
    "```\n",
    "##### Correctness of Dijkstra\n",
    "Note: We cannot use the Path Relaxation Property, because we may relax the edges in the wrong order (with 0 weight edges?)\n",
    "\n",
    "What we really want to show is that when we add an element to $S$, we must ensure that it has the shortest path.\n",
    "\n",
    "**Proof by contradiction** Lets assume the opposite:\n",
    "- Take the first $u \\in S \\mid u.d \\not = \\delta(\\text{start},u)$.\n",
    "- Take a shortest path to $u$ before we add it to $S$\n",
    "- Along this path, take the 1st vertex $y \\not \\in S$ (it's possible $y = u$)\n",
    "- $x = y.predecessor$\n",
    "    - note that $x.d$ is the shortest distance to $x$\n",
    "    - And we relaxed $(x,y)$, so $y.d = \\delta(\\text{start},y)$ must be correct too.\n",
    "        - $ y.d \\le \\delta(\\text{start},u) \\le u.d$ (because no negative edges)\n",
    "    - Thus y should be in S\n",
    "    - If $y$ is in $S$, then, $u$ must equal $y$ and $\\delta(\\text{start},u) = u.d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All pairs shortest path\n",
    "Find the shortest paths between *all* vertices.\n",
    "\n",
    "- Naive solution: n-times BF: $O(n^4)$\n",
    "- Naive solution: n-times Dijkstra: $O(n^3 \\log n)$\n",
    "- Matrix multiplication algorithm $O(n^3 \\log n)$ - can handle negatives\n",
    "- Floyd-Warshall: $O(n^3)$ - still can handle negatives\n",
    "\n",
    "Both of the new techniques use dynamic programming.\n",
    "\n",
    "#### Matrix multiplication algorithm\n",
    "We use the Adjacency matrix representation $W = (w_{i,j}) = $ `0 if i=j, w(i,j) elif i and j adjacent, else +infinity`\n",
    "\n",
    "1. $l_{ij}^{(m)}$ = shortest distance between $i$ and $j$ using $\\le m$ edges.\n",
    "    - $L^{(m)} = (l_{ij}^{(m)})$\n",
    "    - $L^1$ = adjacency matrix\n",
    "    - Goal is to find $L^{n-1}$\n",
    "2. $L^{m+1} = $ \n",
    "    - Each element of the new L is the minimum of $W_j+L_i$\n",
    "    $$l_{ij}^m = \\min_{1\\le k\\le n}(l^{m-1}_{ik} + w_{kj})$$\n",
    "    - Sometimes we write this as $L^m = L^{m-1} \\bigodot W$ where $\\bigodot$ is a new invention\n",
    "\n",
    "It's also reasonably easy to maintain a predecesor matrix alongside this one.\n",
    "\n",
    "```python\n",
    "# Naive solution\n",
    "for i in range(1,n):\n",
    "    for j in range(1, n):\n",
    "        l[i,j] = infinity\n",
    "        for k in range(1, n):\n",
    "            l[i,j] = min(l[i,j], l[i,k]+w[k,j]) # Note: if we placed minimum -> +, and + with *, we get matrix multiplication\n",
    "```\n",
    "We can improve this via repeating squaring:\n",
    "- $L^{(1)} = W$\n",
    "- $L^{(2)} = W^2$ - note: $W^2 = W\\bigodot W$\n",
    "- $L^{(4)} = W^4$\n",
    "- $L^{2^{ \\lceil \\log(n-1) \\rceil}}$\n",
    "\n",
    "\n",
    "#### Floyd-Warshall alrogrithm\n",
    "$d^{(k)}_{ij}$ = shortest distance between i and j using intermmediate vertices in $\\{1,2,...k\\}$\n",
    "\n",
    "- Start with: $D^{(0)} = W$\n",
    "- Goal: $D^{(n)}$\n",
    "\n",
    "We're adding one vertex at a time to our set of vertices, so:\n",
    "$$d^{(k)}_{ij} = min(d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)})$$\n",
    "\n",
    "```python\n",
    "for k in range(1, n):\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, n):\n",
    "            d[i,j] = min(old_d[i,j], old_d[i,k]+old_d[k,j])\n",
    "```\n",
    "Can find **the transitive closure**.\n",
    "Let $G=(V,E)$ be a directed un-weighted graph.\n",
    "\n",
    "$G^*=(V,E^*)$ where $E^*=\\{(i,j) | \\exists \\text{ path } i \\rightarrow j\\}$\n",
    "\n",
    "We can find $E^*$ by running Floyd-Warshall and if d[i,j] is finite, then there is a path between i and j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow networks: Ford Fulkerson algorithm\n",
    "We start with a directed, connected graph, and we have two special vertices:\n",
    "- $s$ = source\n",
    "- $t$ = sink\n",
    "\n",
    "Think of a flow network as a network of pipes each with a capacity of $c(u,v) = \\text{ capacity of edge }(u,v)$ where the source produced 'water' and the sink consumes it. ($c(u,v)$ where $(u,v)\\not\\in G$ is $0$)\n",
    "\n",
    "- We must also assume that there are no antiparallel edges (cycles with only two vertices).\n",
    "\n",
    "Flow = $f(u,v)$. $f: V*V \\rightarrow \\text{Reals}^{\\ge 0}$\n",
    "\n",
    "$$|f| = \\text{outflow - inflow to the source (usually 0)}$$\n",
    "$$|f| = \\sum_{v \\in V} f(s,v) - \\sum_{v \\in V} f(v,s)$$\n",
    "Goal: Maximize $|f|$\n",
    "\n",
    "Antiparallel edges can be fixed by changing 1 -> 2 and 2-> 1 to 1 -> 2, 2 -> new3, new3 -> 1\n",
    "\n",
    "\n",
    "##### Residual network:\n",
    "Represents how much we can increase/decrease our flow between two nodes (edges represent amount of 'water' we can fit into the pipes or how much 'water' we can 'remove'. Edges with flow/weight 0 are deleted.\n",
    "\n",
    "$$G_f = (V, E_f)$$\n",
    "$$E_f = \\{ (u,v) | c_f(u,v) > 0\\}$$\n",
    "\n",
    "- $c_f(u,v) = c(u,v) - f(u,v) $ if $(u,v) \\in E(G)$\n",
    "- $c_f(u,v) = f(u,v) $ if $(v,u) \\in E(G)$\n",
    "- otherwise 0\n",
    "\n",
    "There should be almost twice as many edges in $E_f$ as there are in $E$.\n",
    "\n",
    "##### Augmenting path\n",
    "Just a simple path $P$ from the source to the sink in $G_f$\n",
    "\n",
    "Note that $c_f(P) = \\min \\{c_f(u,v) | (u,v) \\in P\\}$\n",
    "You'll need to augment the flow with $f_p(u,v) = (u,v) \\in P ? c_f(P) : 0$ (I used a ternary operation...)\n",
    "\n",
    "Augmented flow:\n",
    "$$(f \\uparrow f_P)(u,v) = f(u,v) + f_p(u,v) - f_p(v,u) \\text{ iff } (u,v) \\in E(G)$$\n",
    "Total augmented flow is $|f \\uparrow f_p| = |f| + |f_p|$\n",
    "\n",
    "###### Ford Fulkerson algorithm\n",
    "- Initialize $f$ to 0 for all edges.\n",
    "- while there is an augmenting path $P$ in the residual network $G_f$ (Edmonds-Karp always selects the path with the fewest edges, but that isn't too important)\n",
    "    - augment $f$ along the path $P$\n",
    "- Return $f$\n",
    "\n",
    "\n",
    "#### How do we know that the flow is maximum?\n",
    "We're showing that  if $\\not \\exists$ augmenting path, flow is maximum.\n",
    "\n",
    "Let a cut be one of $\\{(S,T) | S \\subset E(G), T \\subset E(G), s \\in S, t \\in T\\} $ where $s$ is the source and $t$ is the sink.\n",
    "\n",
    "Capacity of the cut: $$c(S,T) = \\sum_{u\\in S} \\sum_{v \\in T} c(u,v)$$\n",
    "\n",
    "Note that the flow is at most the copacity ofthe cut. $|f| = f(S,T) \\le c(S,T)$\n",
    "(note that the flow across the cut, $f(S,T)$ is $\\sum\\sum f(u,v) - \\sum\\sum f(v,u)$\n",
    "\n",
    "###### Max flow min cut thm: (will continue tomorrow)\n",
    "The following are equivalent:\n",
    "\n",
    "1. $f$ is a maximum flow\n",
    "2. $\\not \\exists$ augmenting path in $G_f$\n",
    "3. $\\exists$ a cut $(S,T), |f| = c(S,T)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday Feb 23\n",
    "\n",
    "#### Max-Flow min-cut theorem (Ford-Fulkerson)\n",
    "1. $f$ is a max flow\n",
    "2. $\\not \\exists$ augmenting path\n",
    "3. $\\exists$ a cut $(S,T)$ where $|f| = c(S,T)$\n",
    "\n",
    "These are all equivalent:\n",
    "\n",
    "- 1 -> 2 is trivial\n",
    "- 3 -> 1 is trivial ($|f| = f(S,T) \\le c(S,T)$)\n",
    "- 2 -> 3 (slightly trickier)\n",
    "\n",
    "Let us assume there are no augmenting paths in $G_f$.\n",
    "\n",
    "Let $S = \\{ u \\text{ } | \\text{ } \\exists \\text{ a path from s to u in } G_f\\}$\n",
    "\n",
    "We have to show that for this particular cut, $|f| = c(S,T)$.\n",
    "\n",
    "Remember:\n",
    "$$|f| = f(S,T) = \\sum_{u \\in S} \\sum_{v \\in t} (f(u,v) - f(v,u))$$\n",
    "\n",
    "Because $S$ contains all vertices reachable from $s$, we know that any edges must be filled to capacity thus $f(u,v) = c(u,v)$ and $f(v,u) = 0$, thus $|f| = f(S,T) = c(S,T)$\n",
    "\n",
    "\n",
    "###### Time $O(I\\cdot E)$\n",
    "$I$ = # of iterations\n",
    "\n",
    "Assumptions:\n",
    "Integrality condition: All $c(u,v)$ are integers\n",
    "\n",
    "In each iteration $|f|$ must increase by at least 1.\n",
    "So, $I \\le f^*$ (maximum flow).\n",
    "\n",
    "If we don't assume that all $c(u,v)$ are integers, it may be divergent ?\n",
    "\n",
    "##### Edmonds-Karp method\n",
    "We always pick the shortest augmenting path (counting edges).\n",
    "$I \\le V/2 \\cdot E$\n",
    "\n",
    "Thus, $O(E^2 V) = O(n^5)$\n",
    "\n",
    "$(u,v)$ is a critical edge if $c_f(u,v) = c_f(P)$. Thus each edge can become critical at most $\\le V/2$ times.\n",
    "\n",
    "Let $\\delta_f(s,v)$ = shortest distance to v from s in $G_f$\n",
    "We know that $(u,v)$ is on the shortest path (on $G_f$, not necessarily on $G$) when it becomes critical for the $1^{st}$ time. Thus $\\delta_f(s,v) = \\delta_f(s,u) + 1$\n",
    "\n",
    "It can become critical again when we send flow along $(v,u)$, and then reverse it along $(u,v)$ but now, $\\delta_f(s,u) = \\delta_f(s,v) + 1 = \\delta_{f \\text{ old}} (s,u) + 2$\n",
    "\n",
    "\n",
    "#### Application of flow networks for bipartite graph matching\n",
    "- Assume we have a: Unweighted bipartite graph G\n",
    "    - Bipartite graph = graph with two sets of vertices ($L$ and $R$) where vertices in $L$ are only neighbors of vertices in $R$ and vice versa.\n",
    "    - Matching $M$ = subset of $G$ where all edges are disjoint (don't share edges)\n",
    "\n",
    "Let's connect $s$ to all the elements in $L$, and $t$ have an edge to all elements of $R$.\n",
    "\n",
    "The size of the matching ($|M|$) is $|f|$ in this new graph. (note $c(u,v) = 1$ for all edges)\n",
    "\n",
    "Running time is $O(VE) = O(n^3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P = NP\n",
    "#### $P$ = problems solvable in polynomial time ($O(n^c)$)\n",
    "To get $P$ algorithm from an Optimization problem, we convert it to a Decision problem.\n",
    "\n",
    "*Example:*\n",
    "Find a maximum Clique (complete subgraph) of a graph\n",
    "\n",
    "We take what initially appears to an $NP$ complete problem, \n",
    "\n",
    "CLIQUE = {(G, k) | G has a clique of size k}\n",
    "\n",
    "#### $NP$ = problems we can verify in polynomial time $O(n^c)$\n",
    "Another definition is that: Languages accepted by polynomial time Non-deterministic Turing Machine. (NP stands for Non-polynomial).\n",
    "\n",
    "*Example: Hamiltonian Cycle (unweighted travelling salesman problem)*\n",
    "\n",
    "\n",
    "Language $L \\in NP$ if there is a polynomial time algorithm $A(x,y)$ such that:\n",
    "\n",
    "$x \\in L \\iff \\exists \\text{ a certificate } y, |y| = O(|x|^c)$ then $A(x,y)$ is yes.\n",
    "\n",
    "\n",
    "Obviously, $P \\subseteq NP$.\n",
    "\n",
    "**NP Complete** (NPC) are the problems we thing are in $NP$ but not $P$\n",
    "\n",
    "### Polynomial time reduction\n",
    "\n",
    "$L_1 \\le_p L_2$ is reducible to $L_2$ in polynomial time if there is a polynomial time computable function $f$ such that $ x \\in L_1 \\iff f(x) \\in L_2$\n",
    "\n",
    "$$L_1 \\le_p L_2, L_2 \\in P \\implies L_1 \\in P$$\n",
    "\n",
    "\n",
    "##### $L \\in NPC$\n",
    "1. $L \\in NP$\n",
    "2. L is NP hard $\\forall L' \\in NP, L' \\le_p L$ (All NP problems are reducible to L)\n",
    "    - If we can show that for some $L$, $L \\in P \\cup NPC \\implies P = NPC$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notes to self:\n",
    "\n",
    "Showing Hamiltonian cycle * polynomial $\\ge$ travelling salesman problem:\n",
    "\n",
    "1. find Min-spanning tree of travelling salesman graph\n",
    "2. Is there a Hamcycle in the MST?\n",
    "3. Add the edge not in the MST that has the least weight.\n",
    "4. Go back to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "## Approximation algorithms for NPC problems\n",
    "\n",
    "\n",
    "\n",
    "Let:\n",
    "- $C^*$= optimal answer\n",
    "- $C$ = actual result of algorithms\n",
    "- Want to find the bound of $\\rho \\ge \\max(\\frac{C^*}{C}, \\frac{C}{C^*}) \\ge 1$\n",
    "    - Refer to the algorithm as a $\\rho$ approximation algorithm.\n",
    "    - ($\\rho$ can be a function of $n$)\n",
    "    - Ideal goal would be for $\\rho = 1+\\epsilon$ for any small $\\epsilon > 0$\n",
    "    \n",
    ".\n",
    "- In a Polytime approx scheme (PAS):\n",
    "    if $(1+\\epsilon)$ approximation algorithm, time is polynomial in $n$\n",
    "- In a Fully PAS (FPAS):\n",
    "    time is polynomial in $n$ and in $1/\\epsilon$\n",
    "    \n",
    "\n",
    "### Polytime 2 - approx alg for Vertex covering\n",
    "Greedy algorithm returns a $C$ where $C \\le 2|C^*|$\n",
    "\n",
    "Vertex cover is:\n",
    "\n",
    "$V' \\subseteq V$ for each edge $(u,v) \\in E$, either $u$ or $v$ (or both) bolongs to $V'$\n",
    "\n",
    "```python\n",
    "# Gives a set of vertices that covers the edge set E\n",
    "# It returns a set C that is at most |C| = 2|C*|\n",
    "# (|C*| >= the edge set picked = 1/2 * |C|)\n",
    "def vertex_cover(E):\n",
    "    C = []\n",
    "    E_prime = E # Edges\n",
    "\n",
    "    while not E_prime.empty():\n",
    "        u,v = E_prime[0]\n",
    "        C = C + [u,v]\n",
    "        E_prime = list(filter(lambda e: (u not in e) and ( v not in e), E_prime))\n",
    "    return C\n",
    "```\n",
    "\n",
    "### (metric) Travelling Salesman problem  (2 approximation algorithm)\n",
    "For this to work, the cost function $c(u,v)$ must satisfy the triangle inequality.\n",
    "\n",
    "**Triangle inequality:** given $u,v,w \\in V$, $c(u,w) \\le c(u,v) + c(u,w)$ (all edges must be connected)\n",
    "\n",
    "Output tour = 2*optimal tour. ($|H| \\le 2* |H^*|$)\n",
    "\n",
    "Algorithm:\n",
    "- Pick an arbitrary root r\n",
    "- Find a minimum spanning tree with root r (via Prim's algorithm or similar)\n",
    "- $H$ = preorder walk of the tree.\n",
    "\n",
    "**\"Proof\"**\n",
    "\n",
    "If we take $H*$, we know its cost is $\\ge$ the cost of the MST. ($H*$ has one edge more than the MST, and the MST contains the minimum possible edges).\n",
    "\n",
    "```python\n",
    "cost(preorder_walk) <= cost(full_walk) = 2 * cost(minimum_spanning_tree) <= 2 * c(H*)\n",
    "```\n",
    "\n",
    "###### General Travelling Salesman problem\n",
    "If we could approximate in polytime withing a constant $\\rho$ factor, than $P=NP$\n",
    "\n",
    "(Hardness of approximation results - hot research area)\n",
    "\n",
    "Let's assume the reverse:\n",
    "\n",
    "We're going to show that Hamiltonian Cycle $\\in$ P if we have an algorithm $A$ that solves the travelling salesman problem in.\n",
    "\n",
    "We want to find if G contains a Ham. Cycle\n",
    "\n",
    "But we're going to solve it like a travelling salesman problem so $c(u,v)$ = if $(u,v) \\in E$ then 1 else $\\rho |V| + 1$.\n",
    "Then we use $A$ to find an approximate result.\n",
    "And if the final cost is $\\le \\rho |V|$, then there's a hamiltonian cycle.\n",
    "Thus the Hamiltonian cycle problem must be in P.\n",
    "\n",
    "\n",
    "Note: For the clique problem, $\\rho$ must be 'larger' than $n^{1/3}$ (at least acording to current research)\n",
    "\n",
    "### Intermediate problems\n",
    "Problems we think are probably in $P$, but we can't show it.\n",
    "\n",
    "1. Linear programming (Placed in P in 1980s\n",
    "2. Primality (Placed in P in 2000s)\n",
    "3. Graph iso (Almost placed in P very recently)\n",
    "4. Factorization (the professor thinks we'll find an algorithm in $P$ that will solve this problem. That'll break RSA encryption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def Quicksort(A, p, r):\n",
    "    if p < r:\n",
    "        q = Partition(A, p, r)\n",
    "        Quicksort(A, p, q-1)\n",
    "        Quicksort(A,q+1, r)\n",
    "def Partition(A, p, r):\n",
    "    # A becomes: [<x..., >x..., undecided..., x]\n",
    "    # Pivot element is at A[r]\n",
    "    \n",
    "    # To randomize:\n",
    "    # i = random(p, r)\n",
    "    # A[i], A[r-1] = \n",
    "    \n",
    "    i=p\n",
    "    for j in range(p, r):\n",
    "        if A[j] < A[r]:\n",
    "            A[i], A[j] = A[j], A[i]\n",
    "            i+=1\n",
    "    A[i], A[r] = A[r], A[i]\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "x = list(range(100))\n",
    "shuffle(x)\n",
    "Quicksort(x, 0, len(x)-1)\n",
    "sorted(x) == x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def lcs(x,y):\n",
    "    #make_lcs_len_subseq\n",
    "    table = np.zeros((len(x)+1,len(y)+1))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            if x[i] == y[j]:\n",
    "                table[i+1, j+1] = table[i,j] + 1\n",
    "            else:\n",
    "                table[i+1, j+1] = max(table[i,j+1], table[i+1, j])\n",
    "    # trace back lcs subseq\n",
    "    subseq = \"\"\n",
    "    i = len(x)\n",
    "    j = len(y)\n",
    "    while table[i,j] != 0:\n",
    "        if x[i-1] == y[j-1]: #table[i,j] == table[i-1, j-1]\n",
    "            subseq = x[i-1] + subseq\n",
    "            i += -1\n",
    "            j += -1\n",
    "        elif table[i-1, j] == table[i,j]:\n",
    "            i += -1\n",
    "        elif table[i, j-1] == table[i,j]:\n",
    "            j += -1\n",
    "        else:\n",
    "            # shouldn't get here\n",
    "            print('error')\n",
    "    return subseq\n",
    "\n",
    "lcs(\"spanking\", \"amputation\") == \"pain\" and lcs('abcuvxy', 'bcwxyz') == 'bcxy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
