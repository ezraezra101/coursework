{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack on Neural Networks\n",
    "In this question, we will implement fast gradient sign attack (FGSM) on a convolution neural network for MNIST dataset. This reveals the striking lack of robustness present in neural networks. FGSM was first introduced by Goodfellow et al. in 2015. Check out their paper: [Explaining and harnessing adversarial examples](https://arxiv.org/pdf/1412.6572.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(levelname)s %(asctime)s %(name)s %(message)s')\n",
    "\n",
    "from utils import data_mnist\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(u'X_train shape:', (60000, 28, 28, 1))\n",
      "(u'X_test shape:', (10000, 28, 28, 1))\n"
     ]
    }
   ],
   "source": [
    "#choose subset of images in the dataset\n",
    "train_start = 0\n",
    "train_end = 60000\n",
    "test_start = 0\n",
    "test_end = 10000\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                              train_end=train_end,\n",
    "                                              test_start=test_start,\n",
    "                                              test_end=test_end)\n",
    "#(we will only need the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load model\n",
    "Loading a pre-learned model in tensorflow is simple. We need to first load the meta data which is the computation graph. Then, load the weights. Why do we need `tf.Session()` to load a model? Remember that the model variables have no value without the session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MNIST_model/model_Q3\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# load the computation graph\n",
    "saver = tf.train.import_meta_graph('MNIST_model/model_Q3.meta')\n",
    "# load the weights\n",
    "saver.restore(sess, 'MNIST_model/model_Q3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1: visualize the model with Tensorboard\n",
    "[Tensorboard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) is a visualization tool that comes with tensorflow. Here, we use it to visualize the model that you just loaded.\n",
    "\n",
    "To start tensorboard, \n",
    "\n",
    "- Go to terminal and navigate to the root directory of the assignment. \n",
    "- Type `tensorboard --logdir=MNIST_model/`. The server will be launched in the terminal and a url will be displayed.\n",
    "- Open the url with a browser and click the Graph tab. You should see the model that you just loaded. How many convolution layers does it have? (3 layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.5: Get tensors from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name('x:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "logits = graph.get_tensor_by_name('fc_1/logits:0')\n",
    "probs = graph.get_tensor_by_name('probs:0')\n",
    "cross_entropy = graph.get_tensor_by_name('cross_entropy:0')\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "preds_label = graph.get_tensor_by_name('preds_label:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.990599989891\n"
     ]
    }
   ],
   "source": [
    "# sanity check: the testing accuracy should be over .99\n",
    "print('test accuracy {}'.format(sess.run(accuracy, feed_dict={\n",
    "    x: X_test, y: Y_test})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Get the output label for the raw image.\n",
    "Why do we use stop gradient here? (to prevent this from influencing the original convolutional neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_max = tf.reduce_max(probs, axis=1, keep_dims=True)\n",
    "model_predict = tf.stop_gradient(tf.to_float(tf.equal(probs, probs_max)))\n",
    "model_predict = model_predict / tf.reduce_sum(model_predict, 1, keep_dims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: calculate the cross entropy loss \n",
    "Use `model_predict` as your y labels.\n",
    "\n",
    "HINT: This time, do not use `tf.reduce_mean`. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=model_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Gradient of the loss w.r.t. x\n",
    "The loss function is a function of the input image x. \n",
    "We want to calculate the gradient of the loss with respect to x.\n",
    "\n",
    "HINT: use `tf.gradients`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad = tf.gradients(loss, x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Get the sign of the gradient.\n",
    "HINT: use `tf.sign` and `tf.stop_gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_grad = tf.stop_gradient(tf.sign(grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: rescale normalized_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 0.3\n",
    "scaled_grad = eps * normalized_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Perturb the raw image\n",
    "\n",
    "Add `scaled_grad` to `x` and let the result be `adv_x` (`adv_x` is the adversarial image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "adv_x = scaled_grad + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Clip adv_x\n",
    "Clip the value of `adv_x` so that the values are\n",
    "between 0 and 1.\n",
    "\n",
    "HINT: use `tf.clip_by_value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "adv_x = tf.clip_by_value(adv_x, 0, 1, name='adv_x_clipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Generate adversarial images \n",
    "Store them as `adv_x_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "adv_images = None\n",
    "for idx in range(10):\n",
    "    print(idx,end=' ')\n",
    "    #take 1000 images at a time to do this in batches\n",
    "    first, last = 1000 * idx, 1000 * (idx + 1)\n",
    "    \n",
    "    foo = sess.run(adv_x, feed_dict={\n",
    "        x: X_test[first:last, ...], y: Y_test[first:last]})\n",
    "    \n",
    "    if adv_images is not None:\n",
    "        adv_images = np.concatenate([adv_images, foo], axis=0)#append current batch to total output\n",
    "    else:\n",
    "        adv_images = foo\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Accuracy on adversarial images\n",
    "Now check the accuracy on the modified test images. You should expect to see the accuracy drop dramatically to around 0.11!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1146\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: adv_images, y: Y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Save sample adversarial images\n",
    "Maybe the reason for such a low accuracy is that the modified test images are unrecognizable after the process? Save a few of them so you can check for yourself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the classification label (digit) given to the adversarial image\n",
    "label_hat = sess.run(tf.argmax(logits, axis=1), feed_dict={x: adv_images, y: Y_test})\n",
    "\n",
    "if not os.path.exists('MNIST_noisy_imgs'):\n",
    "    os.makedirs('MNIST_noisy_imgs')\n",
    "\n",
    "#save first 10\n",
    "for idx, img in enumerate(adv_images[:10]):\n",
    "    im = Image.fromarray(np.uint8(img * 255).squeeze())\n",
    "    #save each image with its corresponding predicted label in the filename\n",
    "    im.save(os.path.join('MNIST_noisy_imgs', 'im{}_pred_label_{}.png'.format(idx, label_hat[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
